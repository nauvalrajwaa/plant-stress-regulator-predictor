{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "P9euTnhurcVv",
        "outputId": "0b246adf-bf9f-4608-e8ef-ac851f8d012a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:11\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Install Conda Colab\n",
        "#@markdown This cell will restart kernel / session\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DNABERT Wajib Python 3.6 karena ketergantungan library lama\n",
        "!conda create -n myenv python=3.6 -y\n",
        "\n",
        "#@title Install dependencies ke dalam 'myenv'\n",
        "#@markdown Script ini disesuaikan untuk **DNABERT** (PyTorch, Transformers 2.11).\n",
        "\n",
        "# 1. Definisikan lokasi PIP dan PYTHON milik environment baru\n",
        "my_pip = \"/usr/local/envs/myenv/bin/pip\"\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\" # Kita butuh ini untuk run script nanti\n",
        "\n",
        "print(\">>> Memulai instalasi dependencies untuk DNABERT (Python 3.6)...\")\n",
        "\n",
        "# 2. Instalasi PyTorch (Versi Lama yang Kompatibel CUDA Colab)\n",
        "# Menggunakan PyTorch 1.7.1 yang stabil untuk Transformers 2.x\n",
        "!$my_pip install -q --no-warn-conflicts torch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# 3. Instalasi Transformers & Dependencies Inti\n",
        "# Transformers 2.11.0 adalah syarat mutlak DNABERT\n",
        "!$my_pip install -q --no-warn-conflicts transformers==2.11.0\n",
        "!$my_pip install -q --no-warn-conflicts tensorboardX\n",
        "!$my_pip install -q --no-warn-conflicts protobuf==3.20.0\n",
        "\n",
        "# 4. Instalasi Numpy & Scipy (Versi Lama)\n",
        "# Numpy > 1.20 sering error dengan Transformers lama\n",
        "!$my_pip install -q --no-warn-conflicts numpy==1.19.5\n",
        "!$my_pip install -q --no-warn-conflicts scipy==1.5.4\n",
        "!$my_pip install -q --no-warn-conflicts scikit-learn\n",
        "!$my_pip install -q --no-warn-conflicts pandas matplotlib\n",
        "!$my_pip install -q --no-warn-conflicts pyahocorasick matplotlib biopython\n",
        "!$my_pip install -q --no-warn-conflicts statsmodels\n",
        "\n",
        "# 5. Instalasi Bioinformatika\n",
        "!$my_pip install -q --no-warn-conflicts biopython\n",
        "!$my_pip install -q --no-warn-conflicts weblogo # Wajib untuk visualisasi motif\n",
        "\n",
        "print(\"\\n>>> âœ… Instalasi ke dalam 'myenv' selesai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "7z61LZTKrvYC",
        "outputId": "ffb0489a-96fb-466c-fdf8-f2f3d0f491ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.11.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2026.1.4   |       hbd8a1cb_0         143 KB  conda-forge\n",
            "    icu-78.2                   |       h33c6efd_0        12.1 MB  conda-forge\n",
            "    ld_impl_linux-64-2.45      |default_hbd61a6d_105         714 KB  conda-forge\n",
            "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
            "    libgcc-15.2.0              |      he0feb66_16        1018 KB  conda-forge\n",
            "    libgcc-ng-15.2.0           |      h69a702a_16          27 KB  conda-forge\n",
            "    libgomp-15.2.0             |      he0feb66_16         589 KB  conda-forge\n",
            "    liblzma-5.8.1              |       hb9d3cd8_2         110 KB  conda-forge\n",
            "    liblzma-devel-5.8.1        |       hb9d3cd8_2         430 KB  conda-forge\n",
            "    libnsl-2.0.1               |       hb9d3cd8_1          33 KB  conda-forge\n",
            "    libsqlite-3.51.2           |       hf4e2dac_0         921 KB  conda-forge\n",
            "    libstdcxx-15.2.0           |      h934c35e_16         5.6 MB  conda-forge\n",
            "    libstdcxx-ng-15.2.0        |      hdf11a46_16          27 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    openssl-1.1.1w             |       hd590300_0         1.9 MB  conda-forge\n",
            "    pip-21.3.1                 |     pyhd8ed1ab_0         1.2 MB  conda-forge\n",
            "    python-3.6.15              |hb7a2778_0_cpython        38.4 MB  conda-forge\n",
            "    python_abi-3.6             |          2_cp36m           4 KB  conda-forge\n",
            "    readline-8.3               |       h853b02a_0         337 KB  conda-forge\n",
            "    setuptools-58.0.4          |   py36h5fab9bb_2         966 KB  conda-forge\n",
            "    sqlite-3.51.2              |       h04a0ce9_0         179 KB  conda-forge\n",
            "    tk-8.6.13                  |noxft_ha0e22de_103         3.1 MB  conda-forge\n",
            "    wheel-0.37.1               |     pyhd8ed1ab_0          31 KB  conda-forge\n",
            "    xz-5.8.1                   |       hbcc6ac9_2          23 KB  conda-forge\n",
            "    xz-gpl-tools-5.8.1         |       hbcc6ac9_2          33 KB  conda-forge\n",
            "    xz-tools-5.8.1             |       hb9d3cd8_2          94 KB  conda-forge\n",
            "    zstd-1.5.7                 |       hb78ec9c_6         587 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        69.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2026.1.4-hbd8a1cb_0 \n",
            "  icu                conda-forge/linux-64::icu-78.2-h33c6efd_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.45-default_hbd61a6d_105 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.2.0-he0feb66_16 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.2.0-h69a702a_16 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.2.0-he0feb66_16 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_2 \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.8.1-hb9d3cd8_2 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.51.2-hf4e2dac_0 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-15.2.0-h934c35e_16 \n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.2.0-hdf11a46_16 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-1.1.1w-hd590300_0 \n",
            "  pip                conda-forge/noarch::pip-21.3.1-pyhd8ed1ab_0 \n",
            "  python             conda-forge/linux-64::python-3.6.15-hb7a2778_0_cpython \n",
            "  python_abi         conda-forge/linux-64::python_abi-3.6-2_cp36m \n",
            "  readline           conda-forge/linux-64::readline-8.3-h853b02a_0 \n",
            "  setuptools         conda-forge/linux-64::setuptools-58.0.4-py36h5fab9bb_2 \n",
            "  sqlite             conda-forge/linux-64::sqlite-3.51.2-h04a0ce9_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_ha0e22de_103 \n",
            "  wheel              conda-forge/noarch::wheel-0.37.1-pyhd8ed1ab_0 \n",
            "  xz                 conda-forge/linux-64::xz-5.8.1-hbcc6ac9_2 \n",
            "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.8.1-hbcc6ac9_2 \n",
            "  xz-tools           conda-forge/linux-64::xz-tools-5.8.1-hb9d3cd8_2 \n",
            "  zstd               conda-forge/linux-64::zstd-1.5.7-hb78ec9c_6 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.6.15        | 38.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "icu-78.2             | 12.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 1.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1018 KB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 966 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 714 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.51.2        | 179 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | :   2% 0.024456718790080014/1 [00:00<00:04,  4.21s/it]\u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :   5% 0.050356734516574526/1 [00:00<00:01,  2.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 1.9 MB    | :   8% 0.07538611765788518/1 [00:00<00:01,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :   0% 0.00040738642512046545/1 [00:00<05:23, 323.85s/it]\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.35s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | :  42% 0.4183386108829476/1 [00:00<00:00,  2.37it/s]  \u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :  89% 0.8868380467641181/1 [00:00<00:00,  5.02it/s]  \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.34it/s]                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :   8% 0.07740342077288843/1 [00:00<00:02,  2.50s/it]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1018 KB   | :   2% 0.0157115759715688/1 [00:00<00:16, 17.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | :  86% 0.8572723533785942/1 [00:00<00:00,  3.28it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  19% 0.18780514198053458/1 [00:00<00:01,  1.43s/it]\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | : 100% 1.0/1 [00:00<00:00,  5.02it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | :   1% 0.013012954974889858/1 [00:00<00:27, 27.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 966 KB    | :   2% 0.016569361446502017/1 [00:00<00:21, 21.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | :   2% 0.017377875452902394/1 [00:00<00:23, 23.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  28% 0.28028186048288023/1 [00:00<00:00,  1.28s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | : 100% 1.0/1 [00:00<00:00, 23.45s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | :  59% 0.5855829738700435/1 [00:00<00:00,  1.66it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   2% 0.018375108367605347/1 [00:00<00:24, 25.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 714 KB    | :   2% 0.02241831558869287/1 [00:00<00:21, 22.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  37% 0.3715364197098645/1 [00:00<00:00,  1.23s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.66it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 714 KB    | : 100% 1.0/1 [00:00<00:00, 22.46s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | :   3% 0.027158021760895365/1 [00:00<00:20, 21.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | : 100% 1.0/1 [00:00<00:00,  3.28it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:00<00:00, 21.15s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | :   3% 0.027244231968405738/1 [00:00<00:21, 21.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:00<00:00, 21.87s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  52% 0.5157512142025092/1 [00:00<00:00,  1.02it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | :   5% 0.047479808620205/1 [00:00<00:12, 13.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:00<00:00, 16.67s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:00<00:00, 13.24s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.51.2        | 179 KB    | :   9% 0.08938449955809664/1 [00:00<00:06,  7.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | :  11% 0.11182167500460691/1 [00:00<00:05,  6.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:00<00:00,  6.05s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.51.2        | 179 KB    | : 100% 1.0/1 [00:00<00:00,  7.29s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | :  17% 0.1699003453174743/1 [00:00<00:03,  4.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :  15% 0.1451272875440679/1 [00:00<00:04,  4.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:00<00:00,  4.06s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  64% 0.6351154367628056/1 [00:00<00:00,  1.08it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | :  81% 0.8127359181153285/1 [00:00<00:00,  1.29it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1018 KB   | : 100% 1.0/1 [00:00<00:00,  1.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1018 KB   | : 100% 1.0/1 [00:00<00:00,  1.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | : 100% 1.0/1 [00:01<00:00,  5.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:01<00:00,  5.34it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | : 100% 1.0/1 [00:01<00:00,  1.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.6.15        | 38.4 MB   | : 100% 1.0/1 [00:01<00:00,  1.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 966 KB    | : 100% 1.0/1 [00:01<00:00,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-58.0.4    | 966 KB    | : 100% 1.0/1 [00:01<00:00,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.3.1           | 1.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 714 KB    | : 100% 1.0/1 [00:02<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 714 KB    | : 100% 1.0/1 [00:02<00:00,  2.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:02<00:00,  2.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:02<00:00,  2.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:02<00:00,  2.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:02<00:00,  2.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:02<00:00,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:02<00:00,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:02<00:00,  2.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:02<00:00,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:02<00:00,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.51.2        | 179 KB    | : 100% 1.0/1 [00:02<00:00,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.51.2        | 179 KB    | : 100% 1.0/1 [00:02<00:00,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.6.15        | 38.4 MB   | : 100% 1.0/1 [00:08<00:00,  1.34s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            ">>> Memulai instalasi dependencies untuk DNABERT (Python 3.6)...\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588.0 MB 8.2 kB/s             \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.5 MB 32.3 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.6 MB 7.8 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.8 MB 39.1 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1 MB 41.0 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 674 kB 9.1 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3 MB 33.6 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 2.3 MB/s             \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759 kB 40.7 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 9.6 MB/s             \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880 kB 37.0 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40 kB 7.7 MB/s             \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 60.6 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104 kB 71.4 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159 kB 72.5 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70 kB 10.5 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 74.2 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 9.6 MB/s             \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 309 kB 33.8 MB/s            \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101 kB 6.7 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 291 kB 64.5 MB/s            \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'protobuf' candidate (version 4.21.0 at https://files.pythonhosted.org/packages/27/82/986065ef305c0989c99d8ef3f29e58a03fac6e64bb2c36ffe64500cc6955/protobuf-4.21.0-py3-none-any.whl#sha256=4e78116673ba04e01e563f6a9cca2c72db0be8a3e1629094816357e81cc39d36 (from https://pypi.org/simple/protobuf/))\n",
            "Reason for being yanked: Required python version not configured correctly (https://github.com/protocolbuffers/protobuf/issues/10076)\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement protobuf==3.20.0 (from versions: 2.0.0b0, 2.0.3, 2.3.0, 2.4.1, 2.5.0, 2.6.0, 2.6.1, 3.0.0a2, 3.0.0a3, 3.0.0b1, 3.0.0b1.post1, 3.0.0b1.post2, 3.0.0b2, 3.0.0b2.post1, 3.0.0b2.post2, 3.0.0b3, 3.0.0b4, 3.0.0, 3.1.0, 3.1.0.post1, 3.2.0rc1, 3.2.0rc1.post1, 3.2.0rc2, 3.2.0, 3.3.0, 3.4.0, 3.5.0.post1, 3.5.1, 3.5.2, 3.5.2.post1, 3.6.0, 3.6.1, 3.7.0rc2, 3.7.0rc3, 3.7.0, 3.7.1, 3.8.0rc1, 3.8.0, 3.9.0rc1, 3.9.0, 3.9.1, 3.9.2, 3.10.0rc1, 3.10.0, 3.11.0rc1, 3.11.0rc2, 3.11.0, 3.11.1, 3.11.2, 3.11.3, 3.12.0rc1, 3.12.0rc2, 3.12.0, 3.12.1, 3.12.2, 3.12.4, 3.13.0rc3, 3.13.0, 3.14.0rc1, 3.14.0rc2, 3.14.0rc3, 3.14.0, 3.15.0rc1, 3.15.0rc2, 3.15.0, 3.15.1, 3.15.2, 3.15.3, 3.15.4, 3.15.5, 3.15.6, 3.15.7, 3.15.8, 3.16.0rc1, 3.16.0rc2, 3.16.0, 3.17.0rc1, 3.17.0rc2, 3.17.0, 3.17.1, 3.17.2, 3.17.3, 3.18.0rc1, 3.18.0rc2, 3.18.0, 3.18.1, 3.18.3, 3.19.0rc1, 3.19.0rc2, 3.19.0, 3.19.1, 3.19.2, 3.19.3, 3.19.4, 3.19.5, 3.19.6, 4.0.0rc1, 4.0.0rc2, 4.21.0rc1, 4.21.0rc2, 4.21.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for protobuf==3.20.0\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25.9 MB 1.2 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.2 MB 1.2 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.5 MB 9.5 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.5 MB 54.0 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229 kB 73.7 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 509 kB 58.9 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 28.9 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99 kB 6.0 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3 MB 37.1 MB/s            \n",
            "\u001b[?25h  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.5 MB 9.1 MB/s            \n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233 kB 78.9 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466 kB 9.2 MB/s            \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25h\n",
            ">>> âœ… Instalasi ke dalam 'myenv' selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL: Setup DNABERT & Download Model (Flexible Version)\n",
        "import os\n",
        "\n",
        "# @markdown ### Pilih Versi K-mer DNABERT\n",
        "# @markdown Pilih ukuran K-mer (3, 4, 5, atau 6). Default paper adalah 6.\n",
        "kmer_version = \"3\" # @param [\"3\", \"4\", \"5\", \"6\"]\n",
        "\n",
        "# Nama model sesuai repo Hugging Face zhihan1996\n",
        "model_name = f\"DNA_bert_{kmer_version}\"\n",
        "repo_url = f\"https://huggingface.co/zhihan1996/{model_name}\"\n",
        "model_path = f\"/content/DNABERT/{model_name}\"\n",
        "\n",
        "print(f\">>> Anda memilih: {model_name}\")\n",
        "\n",
        "# 1. Clone DNABERT Repository (Main Code)\n",
        "if not os.path.exists('/content/DNABERT'):\n",
        "    print(\">>> Cloning DNABERT Main Repository...\")\n",
        "    !git clone https://github.com/jerryji1993/DNABERT\n",
        "else:\n",
        "    print(\">>> DNABERT Repository sudah ada.\")\n",
        "\n",
        "# 2. Install Package DNABERT ke dalam myenv\n",
        "# Pastikan my_pip terdefinisi (jika cell ini dijalankan terpisah)\n",
        "my_pip = \"/usr/local/envs/myenv/bin/pip\"\n",
        "if not os.path.exists(my_pip):\n",
        "     print(\"âš ï¸ Warning: myenv belum dibuat? Pastikan environment sudah setup.\")\n",
        "else:\n",
        "    print(\">>> Menginstall DNABERT package...\")\n",
        "    %cd /content/DNABERT\n",
        "    !$my_pip install --editable .\n",
        "\n",
        "# 3. Download Model Spesifik dari Hugging Face\n",
        "# Install git-lfs untuk handle file model besar\n",
        "!git lfs install > /dev/null\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\">>> Downloading {model_name} from HuggingFace...\")\n",
        "    # Clone hanya model yang dipilih\n",
        "    !git clone $repo_url\n",
        "else:\n",
        "    print(f\">>> Model {model_name} sudah ada di folder.\")\n",
        "\n",
        "print(\"\\n>>> Cek isi folder model:\")\n",
        "!ls -lh $model_path\n",
        "\n",
        "# Simpan path model ke variabel environment agar bisa dipakai cell lain (opsional)\n",
        "os.environ['CHOSEN_MODEL_PATH'] = model_path\n",
        "os.environ['CHOSEN_KMER'] = kmer_version\n",
        "print(f\"\\nâœ… SIAP! Path model: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "z-vuwqASrxZN",
        "outputId": "3732d7bb-868a-4128-e127-f03279d2b287"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Anda memilih: DNA_bert_3\n",
            ">>> Cloning DNABERT Main Repository...\n",
            "Cloning into 'DNABERT'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Counting objects: 100% (781/781), done.\u001b[K\n",
            "remote: Compressing objects: 100% (350/350), done.\u001b[K\n",
            "remote: Total 781 (delta 422), reused 722 (delta 408), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (781/781), 11.66 MiB | 13.18 MiB/s, done.\n",
            "Resolving deltas: 100% (422/422), done.\n",
            ">>> Menginstall DNABERT package...\n",
            "/content/DNABERT\n",
            "Obtaining file:///content/DNABERT\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (1.19.5)\n",
            "Collecting tokenizers==0.5.0\n",
            "  Downloading tokenizers-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 7.3 MB/s            \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132 kB 61.9 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (2023.8.8)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/envs/myenv/lib/python3.6/site-packages (from transformers==2.5.0) (0.0.53)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/envs/myenv/lib/python3.6/site-packages (from tqdm>=4.27->transformers==2.5.0) (5.4.0)\n",
            "Collecting botocore<1.27.0,>=1.26.10\n",
            "  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.8 MB 69.4 MB/s            \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79 kB 12.1 MB/s            \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->transformers==2.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->transformers==2.5.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->transformers==2.5.0) (2025.4.26)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from requests->transformers==2.5.0) (1.26.20)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/myenv/lib/python3.6/site-packages (from sacremoses->transformers==2.5.0) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/envs/myenv/lib/python3.6/site-packages (from sacremoses->transformers==2.5.0) (8.0.4)\n",
            "Requirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from sacremoses->transformers==2.5.0) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from botocore<1.27.0,>=1.26.10->boto3->transformers==2.5.0) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/envs/myenv/lib/python3.6/site-packages (from click->sacremoses->transformers==2.5.0) (4.8.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from importlib-resources->tqdm>=4.27->transformers==2.5.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/envs/myenv/lib/python3.6/site-packages (from importlib-metadata->click->sacremoses->transformers==2.5.0) (4.1.1)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, tokenizers, boto3, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.7.0\n",
            "    Uninstalling tokenizers-0.7.0:\n",
            "      Successfully uninstalled tokenizers-0.7.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.11.0\n",
            "    Uninstalling transformers-2.11.0:\n",
            "      Successfully uninstalled transformers-2.11.0\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed boto3-1.23.10 botocore-1.26.10 jmespath-0.10.0 s3transfer-0.5.2 tokenizers-0.5.0 transformers-2.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            ">>> Downloading DNA_bert_3 from HuggingFace...\n",
            "Cloning into 'DNA_bert_3'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 48 (delta 2), reused 0 (delta 0), pack-reused 40 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (48/48), 11.76 KiB | 1.07 MiB/s, done.\n",
            "\n",
            ">>> Cek isi folder model:\n",
            "total 331M\n",
            "-rw-r--r-- 1 root root 1.5K Jan 14 06:20 config.json\n",
            "-rw-r--r-- 1 root root  807 Jan 14 06:20 configuration_bert.py\n",
            "-rw-r--r-- 1 root root 5.4K Jan 14 06:20 dnabert_layer.py\n",
            "-rw-r--r-- 1 root root  12K Jan 14 06:20 LICENSE\n",
            "-rw-r--r-- 1 root root 331M Jan 14 06:20 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root   34 Jan 14 06:20 README.md\n",
            "-rw-r--r-- 1 root root  112 Jan 14 06:20 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root   40 Jan 14 06:20 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  287 Jan 14 06:20 vocab.txt\n",
            "\n",
            "âœ… SIAP! Path model: /content/DNABERT/DNA_bert_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Dummy Data (Flexible)\n",
        "import random\n",
        "import os\n",
        "\n",
        "#@markdown ### ðŸ“ Konfigurasi Data\n",
        "#@markdown Tentukan jumlah sampel untuk Training dan Dev (Validasi).\n",
        "\n",
        "num_train_samples = 500 #@param {type:\"integer\"}\n",
        "num_dev_samples = 100 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### ðŸ§¬ Konfigurasi Sekuens\n",
        "#@markdown Sesuaikan **K-mer** dengan model yang Anda pilih sebelumnya (3-6).\n",
        "kmer_size = \"3\" #@param [\"3\", \"4\", \"5\", \"6\"]\n",
        "sequence_length = 100 #@param {type:\"integer\"}\n",
        "\n",
        "# Konversi parameter\n",
        "k = int(kmer_size)\n",
        "\n",
        "# Fungsi seq2kmer dinamis\n",
        "def seq2kmer(seq, k):\n",
        "    kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
        "    return \" \".join(kmer)\n",
        "\n",
        "# Lokasi Data\n",
        "data_dir = \"/content/DNABERT/examples/sample_data/my_binary_task\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# Fungsi Generate Data\n",
        "def generate_data(filename, n_samples, k, seq_len):\n",
        "    print(f\"Generating {n_samples} lines to {os.path.basename(filename)} with K={k}...\")\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"sequence\\tlabel\\n\") # Header wajib DNABERT\n",
        "        for _ in range(n_samples):\n",
        "            bases = ['A','C','G','T']\n",
        "            # Buat random DNA sequence\n",
        "            seq = \"\".join([random.choice(bases) for _ in range(seq_len)])\n",
        "\n",
        "            # Random label (0 atau 1)\n",
        "            label = random.choice([0, 1])\n",
        "\n",
        "            # Convert ke format K-mer\n",
        "            kmer_seq = seq2kmer(seq, k)\n",
        "\n",
        "            f.write(f\"{kmer_seq}\\t{label}\\n\")\n",
        "\n",
        "# Eksekusi\n",
        "print(f\">>> Memulai Generasi Data (K-mer: {k})...\")\n",
        "generate_data(os.path.join(data_dir, \"train.tsv\"), num_train_samples, k, sequence_length)\n",
        "generate_data(os.path.join(data_dir, \"dev.tsv\"), num_dev_samples, k, sequence_length)\n",
        "\n",
        "print(f\"\\nâœ… Data siap di: {data_dir}\")\n",
        "print(f\"- train.tsv: {num_train_samples} baris\")\n",
        "print(f\"- dev.tsv: {num_dev_samples} baris\")\n",
        "print(f\"- K-mer size: {k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "yd6zrZIpr0QQ",
        "outputId": "2250bdfa-fbd1-4e86-d643-d3d42dc9525b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Memulai Generasi Data (K-mer: 3)...\n",
            "Generating 500 lines to train.tsv with K=3...\n",
            "Generating 100 lines to dev.tsv with K=3...\n",
            "\n",
            "âœ… Data siap di: /content/DNABERT/examples/sample_data/my_binary_task\n",
            "- train.tsv: 500 baris\n",
            "- dev.tsv: 100 baris\n",
            "- K-mer size: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ› ï¸ Fix System Dependencies & Re-install PyTorch (Combined)\n",
        "#@markdown ### ðŸ”§ Perbaikan Environment Otomatis\n",
        "#@markdown Script ini melakukan dua langkah perbaikan vital:\n",
        "#@markdown 1. **Fix Libtinfo:** Memperbaiki error `libtinfo.so.5 missing` dengan membuat symlink ke library sistem yang ada.\n",
        "#@markdown 2. **Fix PyTorch/CUDA:** Menginstall ulang PyTorch versi `1.7.1+cu110` agar kompatibel dengan GPU Tesla T4 di Google Colab.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Tentukan path environment khusus kita\n",
        "my_pip = \"/usr/local/envs/myenv/bin/pip\"\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\"\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\">>> TAHAP 1: MEMPERBAIKI SYSTEM LIBRARIES (libtinfo)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Update dan Install paket legacy\n",
        "!apt-get update -q\n",
        "!apt-get install -y libncurses5 libncursesw5\n",
        "\n",
        "# 2. Buat Symlink Manual (Trik agar sistem membaca libtinfo.so.6 sebagai so.5)\n",
        "# Ini solusi standar untuk error 'libtinfo.so.5: cannot open shared object file'\n",
        "if os.path.exists(\"/usr/lib/x86_64-linux-gnu/libtinfo.so.6\"):\n",
        "    !ln -sf /usr/lib/x86_64-linux-gnu/libtinfo.so.6 /usr/lib/x86_64-linux-gnu/libtinfo.so.5\n",
        "    !ln -sf /usr/lib/x86_64-linux-gnu/libtinfo.so.6 /usr/lib/x86_64-linux-gnu/libtinfo.so\n",
        "    print(\"âœ… Symlink libtinfo berhasil dibuat.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Warning: libtinfo.so.6 tidak ditemukan, mencoba lanjut...\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\">>> TAHAP 2: RE-INSTALL PYTORCH (CUDA 11.0)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 3. Uninstall PyTorch versi bawaan/conda yang mungkin rusak/tidak kompatibel\n",
        "print(\">>> Uninstalling faulty PyTorch versions...\")\n",
        "!$my_pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "# 4. Install PyTorch Spesifik (CUDA 11.0)\n",
        "# Versi ini paling stabil untuk environment DNABERT lama di Colab\n",
        "print(\">>> Installing PyTorch 1.7.1 + CUDA 11.0...\")\n",
        "!$my_pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# 5. Verifikasi Akhir\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\">>> VERIFIKASI GPU DALAM ENVIRONMENT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "cmd = f'{my_python} -c \"import torch; print(\\'Versi PyTorch:\\', torch.__version__); print(\\'GPU Available:\\', torch.cuda.is_available()); print(\\'Device Name:\\', torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\'None\\')\"'\n",
        "!{cmd}\n",
        "\n",
        "print(\"\\nâœ… SELESAI. Jika 'GPU Available' bernilai True, Anda siap lanjut ke Training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "_0yWkM5Y-Q_x",
        "outputId": "2b4f9a54-1fb0-4eca-a087-74f25f94cdc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            ">>> TAHAP 1: MEMPERBAIKI SYSTEM LIBRARIES (libtinfo)\n",
            "==================================================\n",
            "Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,297 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,867 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,602 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,600 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,968 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,637 kB]\n",
            "Fetched 38.5 MB in 22s (1,759 kB/s)\n",
            "Reading package lists...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5\n",
            "The following NEW packages will be installed:\n",
            "  libncurses5 libncursesw5 libtinfo5\n",
            "0 upgraded, 3 newly installed, 0 to remove and 89 not upgraded.\n",
            "Need to get 341 kB of archives.\n",
            "After this operation, 1,274 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libncurses5 amd64 6.3-2ubuntu0.1 [107 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libncursesw5 amd64 6.3-2ubuntu0.1 [134 kB]\n",
            "Fetched 341 kB in 1s (267 kB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libncurses5:amd64.\n",
            "Preparing to unpack .../libncurses5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libncurses5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libncursesw5:amd64.\n",
            "Preparing to unpack .../libncursesw5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libncursesw5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up libncurses5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up libncursesw5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/liblzma.so.5 is not a symbolic link\n",
            "\n",
            "âœ… Symlink libtinfo berhasil dibuat.\n",
            "\n",
            "==================================================\n",
            ">>> TAHAP 2: RE-INSTALL PYTORCH (CUDA 11.0)\n",
            "==================================================\n",
            ">>> Uninstalling faulty PyTorch versions...\n",
            "Found existing installation: torch 1.7.1+rocm3.8\n",
            "Uninstalling torch-1.7.1+rocm3.8:\n",
            "  Successfully uninstalled torch-1.7.1+rocm3.8\n",
            "Found existing installation: torchvision 0.8.2+cu92\n",
            "Uninstalling torchvision-0.8.2+cu92:\n",
            "  Successfully uninstalled torchvision-0.8.2+cu92\n",
            "Found existing installation: torchaudio 0.7.2\n",
            "Uninstalling torchaudio-0.7.2:\n",
            "  Successfully uninstalled torchaudio-0.7.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            ">>> Installing PyTorch 1.7.1 + CUDA 11.0...\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp36-cp36m-linux_x86_64.whl (1156.8 MB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1156.8 MB 759 bytes/s         \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp36-cp36m-linux_x86_64.whl (12.9 MB)\n",
            "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.9 MB 831 kB/s            \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Using cached torchaudio-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (7.6 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch==1.7.1+cu110) (4.1.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from torch==1.7.1+cu110) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from torchvision==0.8.2+cu110) (8.4.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-1.7.1+cu110 torchaudio-0.7.2 torchvision-0.8.2+cu110\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\n",
            "==================================================\n",
            ">>> VERIFIKASI GPU DALAM ENVIRONMENT\n",
            "==================================================\n",
            "Versi PyTorch: 1.7.1+cu110\n",
            "GPU Available: True\n",
            "Device Name: Tesla T4\n",
            "\n",
            "âœ… SELESAI. Jika 'GPU Available' bernilai True, Anda siap lanjut ke Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸš€ Run Training (Fine-Tuning)\n",
        "#@markdown Script ini otomatis menggunakan K-mer dan Model yang sudah Anda pilih sebelumnya.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Pindah ke direktori kerja script\n",
        "%cd /content/DNABERT/examples\n",
        "\n",
        "# 1. Setup Environment & Path\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\"\n",
        "\n",
        "# Ambil konfigurasi dari Environment Variables (diset di langkah sebelumnya)\n",
        "# Jika tidak ada, default ke K-mer 6\n",
        "kmer_size = os.environ.get(\"CHOSEN_KMER\", \"6\")\n",
        "model_path = os.environ.get(\"CHOSEN_MODEL_PATH\", \"/content/DNABERT/DNA_bert_6\")\n",
        "tokenizer_name = f\"dna{kmer_size}\"\n",
        "\n",
        "# Gunakan Absolute Path agar aman\n",
        "data_dir = os.path.abspath(\"./sample_data/my_binary_task\")\n",
        "output_dir = os.path.abspath(\"./ft/my_binary_result\")\n",
        "\n",
        "# 2. Validasi Ketersediaan Model\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"âŒ Error: Folder model tidak ditemukan di {model_path}\")\n",
        "    print(\"Pastikan Anda sudah menjalankan Cell 'Setup DNABERT & Download Model' sebelumnya.\")\n",
        "else:\n",
        "    print(\"=\"*40)\n",
        "    print(f\"âš™ï¸  TRAINING CONFIGURATION\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"ðŸ”¹ K-mer Size      : {kmer_size}\")\n",
        "    print(f\"ðŸ”¹ Tokenizer       : {tokenizer_name}\")\n",
        "    print(f\"ðŸ”¹ Pretrained Model: {model_path}\")\n",
        "    print(f\"ðŸ”¹ Data Dir        : {data_dir}\")\n",
        "    print(f\"ðŸ”¹ Output Dir      : {output_dir}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # 3. Susun Command Training\n",
        "    # Perhatikan parameter --tokenizer_name dan --model_name_or_path yang dinamis\n",
        "    cmd = f\"\"\"\n",
        "    {my_python} run_finetune.py \\\n",
        "        --model_type dna \\\n",
        "        --tokenizer_name {tokenizer_name} \\\n",
        "        --model_name_or_path \"{model_path}\" \\\n",
        "        --task_name dnaprom \\\n",
        "        --do_train \\\n",
        "        --do_eval \\\n",
        "        --data_dir \"{data_dir}\" \\\n",
        "        --max_seq_length 100 \\\n",
        "        --per_gpu_eval_batch_size=16 \\\n",
        "        --per_gpu_train_batch_size=16 \\\n",
        "        --learning_rate 2e-4 \\\n",
        "        --num_train_epochs 3.0 \\\n",
        "        --output_dir \"{output_dir}\" \\\n",
        "        --evaluate_during_training \\\n",
        "        --logging_steps 10 \\\n",
        "        --save_steps 100 \\\n",
        "        --warmup_percent 0.1 \\\n",
        "        --hidden_dropout_prob 0.1 \\\n",
        "        --overwrite_output \\\n",
        "        --n_process 2\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n>>> Memulai Training... (Silakan tunggu, proses ini memakan waktu)\")\n",
        "\n",
        "    # Eksekusi\n",
        "    !{cmd}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "rbcAZXaSr2hU",
        "outputId": "0488c471-95cb-4ac7-ad6f-71294826e201"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT/examples\n",
            "========================================\n",
            "âš™ï¸  TRAINING CONFIGURATION\n",
            "========================================\n",
            "ðŸ”¹ K-mer Size      : 3\n",
            "ðŸ”¹ Tokenizer       : dna3\n",
            "ðŸ”¹ Pretrained Model: /content/DNABERT/DNA_bert_3\n",
            "ðŸ”¹ Data Dir        : /content/DNABERT/examples/sample_data/my_binary_task\n",
            "ðŸ”¹ Output Dir      : /content/DNABERT/examples/ft/my_binary_result\n",
            "========================================\n",
            "\n",
            ">>> Memulai Training... (Silakan tunggu, proses ini memakan waktu)\n",
            "01/14/2026 06:23:34 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "01/14/2026 06:23:34 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/DNA_bert_3/config.json\n",
            "01/14/2026 06:23:34 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:23:34 - INFO - transformers.file_utils -   https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-3/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpd6ygrs4v\n",
            "Downloading: 286B [00:00, 1.02MB/s]       \n",
            "01/14/2026 06:23:34 - INFO - transformers.file_utils -   storing https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-3/vocab.txt in cache at /root/.cache/torch/transformers/e1e7221d086d0af09215b2c6ef3ded41de274c79ace1930c48dfce242a7b36fa.b24b7bce4d95258cccdbc46b651c8283db3a0f1324fb97567c8b22b19970f82c\n",
            "01/14/2026 06:23:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/e1e7221d086d0af09215b2c6ef3ded41de274c79ace1930c48dfce242a7b36fa.b24b7bce4d95258cccdbc46b651c8283db3a0f1324fb97567c8b22b19970f82c\n",
            "01/14/2026 06:23:34 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-3/vocab.txt from cache at /root/.cache/torch/transformers/e1e7221d086d0af09215b2c6ef3ded41de274c79ace1930c48dfce242a7b36fa.b24b7bce4d95258cccdbc46b651c8283db3a0f1324fb97567c8b22b19970f82c\n",
            "01/14/2026 06:23:34 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/DNA_bert_3/pytorch_model.bin\n",
            "01/14/2026 06:23:40 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "01/14/2026 06:23:40 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "01/14/2026 06:23:40 - INFO - __main__ -   finish loading model\n",
            "01/14/2026 06:23:44 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='/content/DNABERT/examples/sample_data/my_binary_task', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0002, local_rank=-1, logging_steps=10, max_grad_norm=1.0, max_seq_length=100, max_steps=-1, model_name_or_path='/content/DNABERT/DNA_bert_3', model_type='dna', n_gpu=1, n_process=2, no_cuda=False, num_rnn_layer=2, num_train_epochs=3.0, output_dir='/content/DNABERT/examples/ft/my_binary_result', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=16, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=16, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=100, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna3', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.0)\n",
            "01/14/2026 06:23:44 - INFO - __main__ -   Creating features from dataset file at /content/DNABERT/examples/sample_data/my_binary_task\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   LOOKING AT /content/DNABERT/examples/sample_data/my_binary_task/train.tsv\n",
            "finish loading examples\n",
            "number of processes for converting feature: 2\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   Writing example 0/250\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   Writing example 0/250\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 27 29 40 18 57 24 18 59 32 51 64 51 62 43 32 49 54 9 23 16 50 57 24 18 59 31 48 50 58 26 26 28 34 59 31 47 48 51 64 51 61 39 13 39 15 48 52 66 57 22 11 29 37 7 14 42 26 26 25 21 7 16 49 55 16 52 67 63 45 38 9 23 15 47 48 52 68 65 56 17 54 10 28 33 55 14 41 24 19 64 50 60 35 61 37 6 10 27 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-251\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 28 36 67 64 50 59 30 42 27 30 41 24 19 61 37 8 18 60 35 63 45 37 7 13 39 13 38 12 33 54 10 27 32 52 67 62 41 21 5 6 11 29 40 17 54 10 27 31 48 52 67 62 43 31 45 39 13 38 10 25 22 12 36 68 66 60 35 63 45 38 10 25 21 8 19 61 38 11 31 46 44 34 58 25 22 10 28 35 62 42 25 22 10 28 36 66 59 29 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 56 19 61 38 12 35 61 37 7 13 37 6 10 26 28 35 63 46 43 31 45 38 10 28 33 56 19 64 49 53 5 8 19 64 52 66 57 24 19 63 45 38 11 29 37 5 5 6 11 30 43 31 48 52 68 66 57 22 10 27 32 52 66 60 36 67 64 52 68 65 54 9 24 17 56 19 64 49 54 11 29 40 17 54 9 23 15 48 52 66 59 30 44 35 62 42 25 23 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-252\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 10 25 23 14 41 23 15 46 44 35 63 45 37 5 7 15 45 38 12 34 57 22 11 30 41 23 14 43 31 47 48 50 57 22 9 22 12 34 58 25 22 11 30 43 32 50 57 24 18 58 26 26 28 33 56 18 59 30 43 32 51 64 51 63 45 40 20 67 64 49 54 12 34 58 28 34 59 29 38 12 34 57 24 19 61 38 10 27 31 48 50 59 32 50 59 30 41 23 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 14 44 36 65 53 8 19 61 37 6 12 36 65 55 13 37 6 11 32 51 63 47 47 45 39 16 50 57 21 7 16 49 55 15 47 48 51 61 39 14 43 30 42 28 33 53 8 20 66 58 27 31 48 51 64 51 63 48 51 61 40 20 65 53 8 20 65 54 11 31 46 41 21 5 8 19 63 46 41 22 12 36 65 54 10 27 31 48 50 60 36 67 64 52 65 53 5 6 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-253\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 63 48 49 53 7 16 49 53 8 18 60 34 59 29 40 19 64 51 61 39 14 41 23 16 50 59 30 42 25 22 10 25 21 5 8 17 55 16 52 65 54 11 31 47 48 50 58 25 23 16 49 54 11 29 38 12 34 58 25 24 19 63 47 47 47 46 42 26 28 34 60 33 56 20 67 62 41 22 12 33 55 14 41 21 6 11 29 37 6 11 30 43 29 39 13 39 13 39 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 48 50 58 26 25 23 14 41 24 19 64 52 66 60 33 54 10 25 21 6 12 33 55 13 37 6 9 21 8 19 62 43 29 37 5 7 14 41 24 18 59 30 43 29 38 9 21 6 12 34 57 21 6 12 33 55 16 51 63 46 42 27 29 38 11 31 47 47 46 41 23 14 41 23 16 50 59 32 49 54 12 34 58 26 25 24 20 66 60 33 55 16 49 55 14 42 28 35 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-254\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 64 52 67 61 39 15 45 39 15 48 52 67 61 38 10 25 23 13 39 16 49 53 6 11 30 42 26 28 35 64 52 67 64 50 58 28 33 55 14 41 24 17 55 13 40 17 56 17 54 9 22 12 36 66 60 33 55 14 43 31 48 49 56 20 68 66 57 24 20 68 67 63 47 46 43 32 50 59 32 52 68 66 60 33 54 12 33 54 12 36 66 58 25 22 10 27 30 44 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 33 53 5 5 5 7 13 37 7 16 49 55 13 40 18 57 21 6 10 26 28 34 57 24 19 64 50 60 34 60 36 66 59 32 50 60 33 56 18 59 32 50 57 23 14 42 27 32 52 66 57 23 15 48 50 60 33 55 13 39 15 45 38 10 28 34 60 35 63 48 50 58 25 22 12 36 68 65 54 9 22 12 35 63 47 48 52 68 65 54 10 27 31 46 42 28 33 54 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   guid: train-255\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   input_ids: 2 51 61 37 8 19 61 39 13 38 9 21 5 6 10 27 32 50 57 24 18 58 25 21 5 7 13 38 9 23 16 51 63 48 51 61 40 17 55 16 51 61 40 19 63 47 45 40 17 55 16 51 61 39 16 49 53 6 9 24 17 56 19 63 48 50 58 25 22 9 23 14 41 21 6 9 21 6 9 21 7 13 39 14 42 27 32 52 65 55 13 38 10 26 27 32 49 53 5 3\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:44 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:44 - INFO - __main__ -   Saving features into cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_train_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:23:44 - INFO - __main__ -   ***** Running training *****\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Num examples = 500\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Num Epochs = 3\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Total optimization steps = 96\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Continuing training from epoch 0\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Continuing training from global step 0\n",
            "01/14/2026 06:23:44 - INFO - __main__ -     Will skip the first 0 steps in the first epoch\n",
            "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/32 [00:00<?, ?it/s]\u001b[A/content/DNABERT/src/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   3% 1/32 [00:00<00:12,  2.47it/s]\u001b[A\n",
            "Iteration:   6% 2/32 [00:00<00:09,  3.13it/s]\u001b[A\n",
            "Iteration:   9% 3/32 [00:00<00:08,  3.39it/s]\u001b[A\n",
            "Iteration:  12% 4/32 [00:01<00:07,  3.55it/s]\u001b[A\n",
            "Iteration:  16% 5/32 [00:01<00:07,  3.61it/s]\u001b[A\n",
            "Iteration:  19% 6/32 [00:01<00:07,  3.57it/s]\u001b[A\n",
            "Iteration:  22% 7/32 [00:02<00:06,  3.64it/s]\u001b[A\n",
            "Iteration:  25% 8/32 [00:02<00:06,  3.68it/s]\u001b[A\n",
            "Iteration:  28% 9/32 [00:02<00:06,  3.70it/s]\u001b[A01/14/2026 06:23:47 - INFO - __main__ -   Creating features from dataset file at /content/DNABERT/examples/sample_data/my_binary_task\n",
            "finish loading examples\n",
            "number of processes for converting feature: 1\n",
            "1 processor started !\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   Writing example 0/100\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   input_ids: 2 43 31 45 39 14 44 33 54 11 32 51 61 37 7 14 44 35 62 42 26 27 29 40 17 55 15 47 48 49 53 6 9 21 8 17 55 13 40 17 56 20 65 54 9 24 18 57 24 17 55 14 41 21 6 12 33 56 17 54 10 27 30 41 24 20 67 62 44 35 63 47 45 38 12 33 55 13 37 5 7 14 41 24 20 65 54 9 22 9 22 10 26 27 31 48 50 57 24 3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   input_ids: 2 25 21 8 17 56 18 57 21 8 18 59 30 42 26 28 34 59 30 42 26 25 21 6 11 29 39 13 38 12 33 55 13 38 10 25 23 14 41 24 19 61 39 16 50 58 28 34 57 21 8 19 63 46 44 35 64 50 57 23 15 46 43 32 49 53 6 11 30 43 29 38 12 36 65 54 9 24 17 55 14 44 33 56 17 56 19 61 40 19 63 45 37 5 7 14 41 21 5 3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   input_ids: 2 5 5 7 15 48 51 61 38 12 33 53 7 16 52 67 64 51 62 42 26 27 30 43 32 49 55 16 52 66 60 36 67 63 45 40 18 57 22 9 22 11 29 38 12 33 55 13 39 14 44 33 55 13 40 17 56 19 62 44 35 61 40 18 60 34 57 21 5 8 17 54 11 30 42 27 32 50 60 34 58 25 23 13 40 17 55 16 51 62 42 28 35 62 41 24 20 66 58 3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   input_ids: 2 23 15 47 48 49 53 8 19 62 43 29 39 15 45 40 18 59 30 44 34 59 29 37 5 7 15 46 42 27 32 51 61 39 13 40 19 61 38 12 34 60 36 65 55 16 49 55 14 44 36 66 60 35 62 44 34 60 35 62 41 24 20 67 64 50 59 29 38 12 35 62 42 25 24 19 63 47 45 40 18 60 36 66 59 32 51 61 40 18 59 31 46 44 35 61 39 14 41 3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   input_ids: 2 18 58 28 35 63 47 45 37 5 6 9 22 12 34 59 30 42 26 27 29 39 14 43 31 48 51 63 48 52 68 65 53 5 7 15 47 47 46 41 21 5 5 6 10 26 27 30 42 27 31 47 46 44 33 55 14 44 35 64 49 54 12 35 63 45 37 7 15 46 43 31 46 41 24 20 66 58 26 28 35 63 47 47 47 45 39 14 41 24 17 55 16 49 53 7 14 43 31 3\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:23:47 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:23:47 - INFO - __main__ -   Saving features into cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:23:47 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:23:47 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:23:47 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 12.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 13.26it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:23:48 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     acc = 0.56\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     auc = 0.44034090909090906\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     f1 = 0.358974358974359\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     precision = 0.28\n",
            "01/14/2026 06:23:48 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.56, \"eval_f1\": 0.358974358974359, \"eval_mcc\": 0.0, \"eval_auc\": 0.44034090909090906, \"eval_precision\": 0.28, \"eval_recall\": 0.5, \"learning_rate\": 0.00019770114942528738, \"loss\": 0.7391205489635467, \"step\": 10}\n",
            "\n",
            "Iteration:  31% 10/32 [00:03<00:11,  1.95it/s]\u001b[A\n",
            "Iteration:  34% 11/32 [00:03<00:09,  2.23it/s]\u001b[A\n",
            "Iteration:  38% 12/32 [00:04<00:08,  2.49it/s]\u001b[A\n",
            "Iteration:  41% 13/32 [00:04<00:06,  2.73it/s]\u001b[A\n",
            "Iteration:  44% 14/32 [00:04<00:06,  2.93it/s]\u001b[A\n",
            "Iteration:  47% 15/32 [00:05<00:05,  3.06it/s]\u001b[A\n",
            "Iteration:  50% 16/32 [00:05<00:05,  3.14it/s]\u001b[A\n",
            "Iteration:  53% 17/32 [00:05<00:04,  3.21it/s]\u001b[A\n",
            "Iteration:  56% 18/32 [00:05<00:04,  3.37it/s]\u001b[A\n",
            "Iteration:  59% 19/32 [00:06<00:03,  3.44it/s]\u001b[A01/14/2026 06:23:51 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:23:51 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 11.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.40it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.71it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:23:51 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     acc = 0.44\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     auc = 0.5247564935064934\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     f1 = 0.3055555555555556\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     precision = 0.22\n",
            "01/14/2026 06:23:51 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.44, \"eval_f1\": 0.3055555555555556, \"eval_mcc\": 0.0, \"eval_auc\": 0.5247564935064934, \"eval_precision\": 0.22, \"eval_recall\": 0.5, \"learning_rate\": 0.00017471264367816095, \"loss\": 0.7264847874641418, \"step\": 20}\n",
            "\n",
            "Iteration:  62% 20/32 [00:07<00:05,  2.19it/s]\u001b[A\n",
            "Iteration:  66% 21/32 [00:07<00:04,  2.49it/s]\u001b[A\n",
            "Iteration:  69% 22/32 [00:07<00:03,  2.76it/s]\u001b[A\n",
            "Iteration:  72% 23/32 [00:07<00:03,  2.98it/s]\u001b[A\n",
            "Iteration:  75% 24/32 [00:08<00:02,  3.16it/s]\u001b[A\n",
            "Iteration:  78% 25/32 [00:08<00:02,  3.30it/s]\u001b[A\n",
            "Iteration:  81% 26/32 [00:08<00:01,  3.41it/s]\u001b[A\n",
            "Iteration:  84% 27/32 [00:08<00:01,  3.50it/s]\u001b[A\n",
            "Iteration:  88% 28/32 [00:09<00:01,  3.44it/s]\u001b[A\n",
            "Iteration:  91% 29/32 [00:09<00:00,  3.47it/s]\u001b[A01/14/2026 06:23:54 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:23:54 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:23:54 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:23:54 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.92it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:23:55 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     acc = 0.44\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     auc = 0.4926948051948052\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     f1 = 0.3055555555555556\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     precision = 0.22\n",
            "01/14/2026 06:23:55 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.44, \"eval_f1\": 0.3055555555555556, \"eval_mcc\": 0.0, \"eval_auc\": 0.4926948051948052, \"eval_precision\": 0.22, \"eval_recall\": 0.5, \"learning_rate\": 0.00015172413793103449, \"loss\": 0.7161472558975219, \"step\": 30}\n",
            "\n",
            "Iteration:  94% 30/32 [00:10<00:00,  2.20it/s]\u001b[A\n",
            "Iteration:  97% 31/32 [00:10<00:00,  2.50it/s]\u001b[A\n",
            "Iteration: 100% 32/32 [00:10<00:00,  2.98it/s]\n",
            "Epoch:  33% 1/3 [00:10<00:21, 10.74s/it]\n",
            "Iteration:   0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   3% 1/32 [00:00<00:08,  3.77it/s]\u001b[A\n",
            "Iteration:   6% 2/32 [00:00<00:08,  3.68it/s]\u001b[A\n",
            "Iteration:   9% 3/32 [00:00<00:07,  3.65it/s]\u001b[A\n",
            "Iteration:  12% 4/32 [00:01<00:07,  3.66it/s]\u001b[A\n",
            "Iteration:  16% 5/32 [00:01<00:07,  3.68it/s]\u001b[A\n",
            "Iteration:  19% 6/32 [00:01<00:07,  3.60it/s]\u001b[A\n",
            "Iteration:  22% 7/32 [00:01<00:06,  3.62it/s]\u001b[A01/14/2026 06:23:57 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:23:57 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:23:57 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:23:57 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.72it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:23:58 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     acc = 0.56\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     auc = 0.5247564935064936\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     f1 = 0.358974358974359\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     precision = 0.28\n",
            "01/14/2026 06:23:58 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.56, \"eval_f1\": 0.358974358974359, \"eval_mcc\": 0.0, \"eval_auc\": 0.5247564935064936, \"eval_precision\": 0.28, \"eval_recall\": 0.5, \"learning_rate\": 0.00012873563218390805, \"loss\": 0.7787079691886902, \"step\": 40}\n",
            "\n",
            "Iteration:  25% 8/32 [00:02<00:10,  2.21it/s]\u001b[A\n",
            "Iteration:  28% 9/32 [00:03<00:09,  2.50it/s]\u001b[A\n",
            "Iteration:  31% 10/32 [00:03<00:07,  2.79it/s]\u001b[A\n",
            "Iteration:  34% 11/32 [00:03<00:06,  3.02it/s]\u001b[A\n",
            "Iteration:  38% 12/32 [00:03<00:06,  3.20it/s]\u001b[A\n",
            "Iteration:  41% 13/32 [00:04<00:05,  3.30it/s]\u001b[A\n",
            "Iteration:  44% 14/32 [00:04<00:05,  3.42it/s]\u001b[A\n",
            "Iteration:  47% 15/32 [00:04<00:04,  3.49it/s]\u001b[A\n",
            "Iteration:  50% 16/32 [00:04<00:04,  3.55it/s]\u001b[A\n",
            "Iteration:  53% 17/32 [00:05<00:04,  3.46it/s]\u001b[A01/14/2026 06:24:01 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:01 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 13.13it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:24:01 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     acc = 0.44\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     auc = 0.5146103896103896\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     f1 = 0.3055555555555556\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     precision = 0.22\n",
            "01/14/2026 06:24:01 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.44, \"eval_f1\": 0.3055555555555556, \"eval_mcc\": 0.0, \"eval_auc\": 0.5146103896103896, \"eval_precision\": 0.22, \"eval_recall\": 0.5, \"learning_rate\": 0.00010574712643678162, \"loss\": 0.719573724269867, \"step\": 50}\n",
            "\n",
            "Iteration:  56% 18/32 [00:06<00:06,  2.19it/s]\u001b[A\n",
            "Iteration:  59% 19/32 [00:06<00:05,  2.46it/s]\u001b[A\n",
            "Iteration:  62% 20/32 [00:06<00:04,  2.63it/s]\u001b[A\n",
            "Iteration:  66% 21/32 [00:06<00:03,  2.80it/s]\u001b[A\n",
            "Iteration:  69% 22/32 [00:07<00:03,  2.96it/s]\u001b[A\n",
            "Iteration:  72% 23/32 [00:07<00:02,  3.15it/s]\u001b[A\n",
            "Iteration:  75% 24/32 [00:07<00:02,  3.29it/s]\u001b[A\n",
            "Iteration:  78% 25/32 [00:08<00:02,  3.38it/s]\u001b[A\n",
            "Iteration:  81% 26/32 [00:08<00:01,  3.44it/s]\u001b[A\n",
            "Iteration:  84% 27/32 [00:08<00:01,  3.50it/s]\u001b[A01/14/2026 06:24:04 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:04 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:04 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:04 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.71it/s]\n",
            "01/14/2026 06:24:05 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     acc = 0.48\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     auc = 0.5178571428571428\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     f1 = 0.39223936418887334\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     mcc = -0.15311555784481912\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     precision = 0.4010840108401084\n",
            "01/14/2026 06:24:05 - INFO - __main__ -     recall = 0.4407467532467533\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.48, \"eval_f1\": 0.39223936418887334, \"eval_mcc\": -0.15311555784481912, \"eval_auc\": 0.5178571428571428, \"eval_precision\": 0.4010840108401084, \"eval_recall\": 0.4407467532467533, \"learning_rate\": 8.275862068965517e-05, \"loss\": 0.7097997725009918, \"step\": 60}\n",
            "\n",
            "Iteration:  88% 28/32 [00:09<00:01,  2.21it/s]\u001b[A\n",
            "Iteration:  91% 29/32 [00:09<00:01,  2.51it/s]\u001b[A\n",
            "Iteration:  94% 30/32 [00:10<00:00,  2.76it/s]\u001b[A\n",
            "Iteration:  97% 31/32 [00:10<00:00,  3.00it/s]\u001b[A\n",
            "Iteration: 100% 32/32 [00:10<00:00,  3.07it/s]\n",
            "Epoch:  67% 2/3 [00:21<00:10, 10.56s/it]\n",
            "Iteration:   0% 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   3% 1/32 [00:00<00:08,  3.73it/s]\u001b[A\n",
            "Iteration:   6% 2/32 [00:00<00:08,  3.67it/s]\u001b[A\n",
            "Iteration:   9% 3/32 [00:00<00:07,  3.66it/s]\u001b[A\n",
            "Iteration:  12% 4/32 [00:01<00:07,  3.66it/s]\u001b[A\n",
            "Iteration:  16% 5/32 [00:01<00:07,  3.68it/s]\u001b[A01/14/2026 06:24:07 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:07 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:07 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:07 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 11.74it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.58it/s]\n",
            "01/14/2026 06:24:08 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     acc = 0.51\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     auc = 0.515422077922078\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     f1 = 0.4954175677067243\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     mcc = -0.006608492628407465\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     precision = 0.49663724253888186\n",
            "01/14/2026 06:24:08 - INFO - __main__ -     recall = 0.4967532467532467\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.51, \"eval_f1\": 0.4954175677067243, \"eval_mcc\": -0.006608492628407465, \"eval_auc\": 0.515422077922078, \"eval_precision\": 0.49663724253888186, \"eval_recall\": 0.4967532467532467, \"learning_rate\": 5.977011494252874e-05, \"loss\": 0.7033327043056488, \"step\": 70}\n",
            "\n",
            "Iteration:  19% 6/32 [00:02<00:12,  2.14it/s]\u001b[A\n",
            "Iteration:  22% 7/32 [00:02<00:10,  2.48it/s]\u001b[A\n",
            "Iteration:  25% 8/32 [00:02<00:08,  2.74it/s]\u001b[A\n",
            "Iteration:  28% 9/32 [00:03<00:07,  2.98it/s]\u001b[A\n",
            "Iteration:  31% 10/32 [00:03<00:06,  3.17it/s]\u001b[A\n",
            "Iteration:  34% 11/32 [00:03<00:06,  3.28it/s]\u001b[A\n",
            "Iteration:  38% 12/32 [00:03<00:05,  3.37it/s]\u001b[A\n",
            "Iteration:  41% 13/32 [00:04<00:05,  3.44it/s]\u001b[A\n",
            "Iteration:  44% 14/32 [00:04<00:05,  3.41it/s]\u001b[A\n",
            "Iteration:  47% 15/32 [00:04<00:04,  3.51it/s]\u001b[A01/14/2026 06:24:10 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:10 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:10 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:10 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.54it/s]\n",
            "01/14/2026 06:24:11 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     acc = 0.54\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     auc = 0.5056818181818181\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     f1 = 0.5398159263705482\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     mcc = 0.09054237262961196\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     precision = 0.5450885668276972\n",
            "01/14/2026 06:24:11 - INFO - __main__ -     recall = 0.5454545454545454\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.54, \"eval_f1\": 0.5398159263705482, \"eval_mcc\": 0.09054237262961196, \"eval_auc\": 0.5056818181818181, \"eval_precision\": 0.5450885668276972, \"eval_recall\": 0.5454545454545454, \"learning_rate\": 3.67816091954023e-05, \"loss\": 0.6753835558891297, \"step\": 80}\n",
            "\n",
            "Iteration:  50% 16/32 [00:05<00:07,  2.20it/s]\u001b[A\n",
            "Iteration:  53% 17/32 [00:05<00:06,  2.49it/s]\u001b[A\n",
            "Iteration:  56% 18/32 [00:06<00:05,  2.76it/s]\u001b[A\n",
            "Iteration:  59% 19/32 [00:06<00:04,  2.98it/s]\u001b[A\n",
            "Iteration:  62% 20/32 [00:06<00:03,  3.10it/s]\u001b[A\n",
            "Iteration:  66% 21/32 [00:06<00:03,  3.15it/s]\u001b[A\n",
            "Iteration:  69% 22/32 [00:07<00:03,  3.22it/s]\u001b[A\n",
            "Iteration:  72% 23/32 [00:07<00:02,  3.27it/s]\u001b[A\n",
            "Iteration:  75% 24/32 [00:07<00:02,  3.31it/s]\u001b[A\n",
            "Iteration:  78% 25/32 [00:08<00:02,  3.36it/s]\u001b[A01/14/2026 06:24:14 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:14 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     Batch size = 16\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  29% 2/7 [00:00<00:00, 12.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  57% 4/7 [00:00<00:00, 11.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 12.84it/s]\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "01/14/2026 06:24:14 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     acc = 0.44\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     auc = 0.47483766233766234\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     f1 = 0.3055555555555556\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     mcc = 0.0\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     precision = 0.22\n",
            "01/14/2026 06:24:14 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.44, \"eval_f1\": 0.3055555555555556, \"eval_mcc\": 0.0, \"eval_auc\": 0.47483766233766234, \"eval_precision\": 0.22, \"eval_recall\": 0.5, \"learning_rate\": 1.3793103448275863e-05, \"loss\": 0.6806056082248688, \"step\": 90}\n",
            "\n",
            "Iteration:  81% 26/32 [00:08<00:02,  2.15it/s]\u001b[A\n",
            "Iteration:  84% 27/32 [00:09<00:02,  2.43it/s]\u001b[A\n",
            "Iteration:  88% 28/32 [00:09<00:01,  2.69it/s]\u001b[A\n",
            "Iteration:  91% 29/32 [00:09<00:01,  2.89it/s]\u001b[A\n",
            "Iteration:  94% 30/32 [00:10<00:00,  3.09it/s]\u001b[A\n",
            "Iteration:  97% 31/32 [00:10<00:00,  3.25it/s]\u001b[A\n",
            "Iteration: 100% 32/32 [00:10<00:00,  3.05it/s]\n",
            "Epoch: 100% 3/3 [00:31<00:00, 10.56s/it]\n",
            "01/14/2026 06:24:16 - INFO - __main__ -    global_step = 96, average loss = 0.7155194884787003\n",
            "01/14/2026 06:24:16 - INFO - __main__ -   Saving model checkpoint to /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:24:16 - INFO - transformers.configuration_utils -   Configuration saved in /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:24:17 - INFO - transformers.modeling_utils -   Model weights saved in /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:24:17 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:24:17 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:24:17 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   Model name '/content/DNABERT/examples/ft/my_binary_result' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/content/DNABERT/examples/ft/my_binary_result' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   Didn't find file /content/DNABERT/examples/ft/my_binary_result/added_tokens.json. We won't load it.\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/vocab.txt\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file None\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/special_tokens_map.json\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/tokenizer_config.json\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   Model name '/content/DNABERT/examples/ft/my_binary_result' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/content/DNABERT/examples/ft/my_binary_result' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   Didn't find file /content/DNABERT/examples/ft/my_binary_result/added_tokens.json. We won't load it.\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/vocab.txt\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file None\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/special_tokens_map.json\n",
            "01/14/2026 06:24:20 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/tokenizer_config.json\n",
            "01/14/2026 06:24:20 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/DNABERT/examples/ft/my_binary_result']\n",
            "01/14/2026 06:24:20 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:24:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:24:20 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:24:22 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_DNA_bert_3_100_dnaprom\n",
            "01/14/2026 06:24:22 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "01/14/2026 06:24:22 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:24:22 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 7/7 [00:00<00:00, 11.75it/s]\n",
            "01/14/2026 06:24:23 - INFO - __main__ -   ***** Eval results  *****\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     acc = 0.42\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     auc = 0.476461038961039\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     f1 = 0.30952380952380953\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     mcc = -0.12747814089845524\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     precision = 0.33854166666666663\n",
            "01/14/2026 06:24:23 - INFO - __main__ -     recall = 0.47483766233766234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ”® Run Prediction & Attention (Flexible)\n",
        "#@markdown Script ini melakukan prediksi dan menghasilkan **Attention Scores** (`atten.npy`) yang dibutuhkan untuk pencarian motif.\n",
        "#@markdown Otomatis menyesuaikan dengan K-mer yang dipilih sebelumnya.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Pindah ke direktori kerja\n",
        "%cd /content/DNABERT/examples\n",
        "\n",
        "# 1. Setup Environment & Path\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\"\n",
        "\n",
        "# Ambil konfigurasi K-mer dari environment (default ke \"6\" jika tidak ada)\n",
        "kmer_size = os.environ.get(\"CHOSEN_KMER\", \"6\")\n",
        "tokenizer_name = f\"dna{kmer_size}\"\n",
        "\n",
        "# Path Folder\n",
        "# Model yang digunakan adalah hasil Fine-Tuning dari langkah sebelumnya\n",
        "trained_model_dir = os.path.abspath(\"./ft/my_binary_result\")\n",
        "data_dir = os.path.abspath(\"./sample_data/my_binary_task\")\n",
        "output_dir = os.path.abspath(\"./ft/my_binary_result\") # Hasil prediksi disimpan di folder yang sama\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"âš™ï¸  PREDICTION CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ðŸ”¹ K-mer Size      : {kmer_size}\")\n",
        "print(f\"ðŸ”¹ Tokenizer       : {tokenizer_name}\")\n",
        "print(f\"ðŸ”¹ Model Source    : {trained_model_dir}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\n>>> Memulai Prediksi & Visualisasi (Generate atten.npy)...\")\n",
        "\n",
        "# 2. Susun Command\n",
        "# Penting: --do_visualize wajib ada untuk langkah Motif Discovery\n",
        "cmd = f\"\"\"\n",
        "{my_python} run_finetune.py \\\n",
        "    --model_type dna \\\n",
        "    --tokenizer_name={tokenizer_name} \\\n",
        "    --model_name_or_path \"{trained_model_dir}\" \\\n",
        "    --task_name dnaprom \\\n",
        "    --do_predict \\\n",
        "    --do_visualize \\\n",
        "    --data_dir \"{data_dir}\" \\\n",
        "    --max_seq_length 100 \\\n",
        "    --per_gpu_eval_batch_size=32 \\\n",
        "    --output_dir \"{output_dir}\" \\\n",
        "    --predict_dir \"{output_dir}\" \\\n",
        "    --n_process 2\n",
        "\"\"\"\n",
        "\n",
        "# 3. Eksekusi\n",
        "!{cmd}\n",
        "\n",
        "# 4. Verifikasi Output\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\">>> VERIFIKASI FILE HASIL\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "atten_file = os.path.join(output_dir, \"atten.npy\")\n",
        "pred_file = os.path.join(output_dir, \"pred_results.npy\")\n",
        "\n",
        "if os.path.exists(atten_file) and os.path.exists(pred_file):\n",
        "    print(f\"âœ… SUKSES: File Attention ditemukan di: {atten_file}\")\n",
        "    print(f\"âœ… SUKSES: File Prediksi ditemukan di: {pred_file}\")\n",
        "    print(\"ðŸ‘‰ Anda siap lanjut ke Tahap 7 (Motif Discovery).\")\n",
        "else:\n",
        "    print(f\"âŒ GAGAL: Salah satu file output tidak ditemukan di {output_dir}\")\n",
        "    print(\"Cek log error di atas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "cellView": "form",
        "id": "69f9A49O_yqo",
        "outputId": "66fc4b8e-f1fa-4974-9b2c-7302ef8805fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT/examples\n",
            "==================================================\n",
            "âš™ï¸  PREDICTION CONFIGURATION\n",
            "==================================================\n",
            "ðŸ”¹ K-mer Size      : 3\n",
            "ðŸ”¹ Tokenizer       : dna3\n",
            "ðŸ”¹ Model Source    : /content/DNABERT/examples/ft/my_binary_result\n",
            "==================================================\n",
            "\n",
            ">>> Memulai Prediksi & Visualisasi (Generate atten.npy)...\n",
            "01/14/2026 06:25:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   Model name '/content/DNABERT/examples/ft/my_binary_result' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming '/content/DNABERT/examples/ft/my_binary_result' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   Didn't find file /content/DNABERT/examples/ft/my_binary_result/added_tokens.json. We won't load it.\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/vocab.txt\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   loading file None\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/special_tokens_map.json\n",
            "01/14/2026 06:25:05 - INFO - transformers.tokenization_utils -   loading file /content/DNABERT/examples/ft/my_binary_result/tokenizer_config.json\n",
            "01/14/2026 06:25:05 - INFO - __main__ -   Predict using the following checkpoint: /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:25:05 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:25:05 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:25:05 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:25:12 - INFO - __main__ -   Creating features from dataset file at /content/DNABERT/examples/sample_data/my_binary_task\n",
            "finish loading examples\n",
            "number of processes for converting feature: 1\n",
            "1 processor started !\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   Writing example 0/100\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   input_ids: 2 43 31 45 39 14 44 33 54 11 32 51 61 37 7 14 44 35 62 42 26 27 29 40 17 55 15 47 48 49 53 6 9 21 8 17 55 13 40 17 56 20 65 54 9 24 18 57 24 17 55 14 41 21 6 12 33 56 17 54 10 27 30 41 24 20 67 62 44 35 63 47 45 38 12 33 55 13 37 5 7 14 41 24 20 65 54 9 22 9 22 10 26 27 31 48 50 57 24 3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   input_ids: 2 25 21 8 17 56 18 57 21 8 18 59 30 42 26 28 34 59 30 42 26 25 21 6 11 29 39 13 38 12 33 55 13 38 10 25 23 14 41 24 19 61 39 16 50 58 28 34 57 21 8 19 63 46 44 35 64 50 57 23 15 46 43 32 49 53 6 11 30 43 29 38 12 36 65 54 9 24 17 55 14 44 33 56 17 56 19 61 40 19 63 45 37 5 7 14 41 21 5 3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   input_ids: 2 5 5 7 15 48 51 61 38 12 33 53 7 16 52 67 64 51 62 42 26 27 30 43 32 49 55 16 52 66 60 36 67 63 45 40 18 57 22 9 22 11 29 38 12 33 55 13 39 14 44 33 55 13 40 17 56 19 62 44 35 61 40 18 60 34 57 21 5 8 17 54 11 30 42 27 32 50 60 34 58 25 23 13 40 17 55 16 51 62 42 28 35 62 41 24 20 66 58 3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   input_ids: 2 23 15 47 48 49 53 8 19 62 43 29 39 15 45 40 18 59 30 44 34 59 29 37 5 7 15 46 42 27 32 51 61 39 13 40 19 61 38 12 34 60 36 65 55 16 49 55 14 44 36 66 60 35 62 44 34 60 35 62 41 24 20 67 64 50 59 29 38 12 35 62 42 25 24 19 63 47 45 40 18 60 36 66 59 32 51 61 40 18 59 31 46 44 35 61 39 14 41 3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   input_ids: 2 18 58 28 35 63 47 45 37 5 6 9 22 12 34 59 30 42 26 27 29 39 14 43 31 48 51 63 48 52 68 65 53 5 7 15 47 47 46 41 21 5 5 6 10 26 27 30 42 27 31 47 46 44 33 55 14 44 35 64 49 54 12 35 63 45 37 7 15 46 43 31 46 41 24 20 66 58 26 28 35 63 47 47 47 45 39 14 41 24 17 55 16 49 53 7 14 43 31 3\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "01/14/2026 06:25:12 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "01/14/2026 06:25:12 - INFO - __main__ -   Saving features into cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_100_dnaprom\n",
            "01/14/2026 06:25:12 - INFO - __main__ -   ***** Running prediction  *****\n",
            "01/14/2026 06:25:12 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:25:12 - INFO - __main__ -     Batch size = 8\n",
            "Predicting: 100% 13/13 [00:00<00:00, 19.66it/s]\n",
            "01/14/2026 06:25:13 - INFO - __main__ -   ***** Pred results  *****\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     acc = 0.42\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     auc = 0.476461038961039\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     f1 = 0.30952380952380953\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     mcc = -0.12747814089845524\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     precision = 0.33854166666666663\n",
            "01/14/2026 06:25:13 - INFO - __main__ -     recall = 0.47483766233766234\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:25:13 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-3/vocab.txt from cache at /root/.cache/torch/transformers/e1e7221d086d0af09215b2c6ef3ded41de274c79ace1930c48dfce242a7b36fa.b24b7bce4d95258cccdbc46b651c8283db3a0f1324fb97567c8b22b19970f82c\n",
            "01/14/2026 06:25:13 - INFO - __main__ -   Calculate attention score using the following checkpoint: /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:25:13 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:25:13 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:25:13 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:25:16 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_100_dnaprom\n",
            "01/14/2026 06:25:16 - INFO - __main__ -   ***** Running prediction  *****\n",
            "01/14/2026 06:25:16 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:25:16 - INFO - __main__ -     Batch size = 8\n",
            "Predicting: 100% 13/13 [00:00<00:00, 20.19it/s]\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:25:16 - INFO - transformers.file_utils -   https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-4/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpx97vp8c1\n",
            "Downloading: 1.31kB [00:00, 4.88MB/s]     \n",
            "01/14/2026 06:25:16 - INFO - transformers.file_utils -   storing https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-4/vocab.txt in cache at /root/.cache/torch/transformers/7e2907c40805f9ae104ef14f1bb0e1d375c6edddace059a06037bdc80e8abe91.29586c1860b95c4db60b7024d64161b951279c64e0d9eeea911f286be8f229ae\n",
            "01/14/2026 06:25:16 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/7e2907c40805f9ae104ef14f1bb0e1d375c6edddace059a06037bdc80e8abe91.29586c1860b95c4db60b7024d64161b951279c64e0d9eeea911f286be8f229ae\n",
            "01/14/2026 06:25:16 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-4/vocab.txt from cache at /root/.cache/torch/transformers/7e2907c40805f9ae104ef14f1bb0e1d375c6edddace059a06037bdc80e8abe91.29586c1860b95c4db60b7024d64161b951279c64e0d9eeea911f286be8f229ae\n",
            "01/14/2026 06:25:16 - INFO - __main__ -   Calculate attention score using the following checkpoint: /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:25:16 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:25:16 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:25:16 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:25:19 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_100_dnaprom\n",
            "01/14/2026 06:25:19 - INFO - __main__ -   ***** Running prediction  *****\n",
            "01/14/2026 06:25:19 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:25:19 - INFO - __main__ -     Batch size = 8\n",
            "Predicting: 100% 13/13 [00:00<00:00, 19.98it/s]\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:25:20 - INFO - transformers.file_utils -   https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-5/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpt3j2_zs7\n",
            "Downloading: 6.17kB [00:00, 21.7MB/s]       \n",
            "01/14/2026 06:25:20 - INFO - transformers.file_utils -   storing https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-5/vocab.txt in cache at /root/.cache/torch/transformers/685498e46a419b3f23df06c611f1f3a88eac034537db33e2f77f448f55b84c64.222d8870b75e875fba4f058daa3d7be681c0401d3ea07303f4e0e646cfe28936\n",
            "01/14/2026 06:25:20 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/685498e46a419b3f23df06c611f1f3a88eac034537db33e2f77f448f55b84c64.222d8870b75e875fba4f058daa3d7be681c0401d3ea07303f4e0e646cfe28936\n",
            "01/14/2026 06:25:20 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-5/vocab.txt from cache at /root/.cache/torch/transformers/685498e46a419b3f23df06c611f1f3a88eac034537db33e2f77f448f55b84c64.222d8870b75e875fba4f058daa3d7be681c0401d3ea07303f4e0e646cfe28936\n",
            "01/14/2026 06:25:20 - INFO - __main__ -   Calculate attention score using the following checkpoint: /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:25:20 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:25:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:25:20 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:25:22 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_100_dnaprom\n",
            "01/14/2026 06:25:22 - INFO - __main__ -   ***** Running prediction  *****\n",
            "01/14/2026 06:25:22 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:25:22 - INFO - __main__ -     Batch size = 8\n",
            "Predicting: 100% 13/13 [00:00<00:00, 19.63it/s]\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "01/14/2026 06:25:23 - INFO - transformers.file_utils -   https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp4o27qwx4\n",
            "Downloading: 28.7kB [00:00, 40.5MB/s]       \n",
            "01/14/2026 06:25:23 - INFO - transformers.file_utils -   storing https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt in cache at /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "01/14/2026 06:25:23 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "01/14/2026 06:25:23 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "01/14/2026 06:25:23 - INFO - __main__ -   Calculate attention score using the following checkpoint: /content/DNABERT/examples/ft/my_binary_result\n",
            "01/14/2026 06:25:23 - INFO - transformers.configuration_utils -   loading configuration file /content/DNABERT/examples/ft/my_binary_result/config.json\n",
            "01/14/2026 06:25:23 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"configuration_bert.BertConfig\",\n",
            "    \"AutoModel\": \"dnabert_layer.BertModel\",\n",
            "    \"AutoModelForMaskedLM\": \"dnabert_layer.BertForMaskedLM\",\n",
            "    \"AutoModelForPreTraining\": \"dnabert_layer.BertForPreTraining\",\n",
            "    \"AutoModelForSequenceClassification\": \"dnabert_layer.DNABertForSequenceClassification\"\n",
            "  },\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 69\n",
            "}\n",
            "\n",
            "01/14/2026 06:25:23 - INFO - transformers.modeling_utils -   loading weights file /content/DNABERT/examples/ft/my_binary_result/pytorch_model.bin\n",
            "01/14/2026 06:25:27 - INFO - __main__ -   Loading features from cached file /content/DNABERT/examples/sample_data/my_binary_task/cached_dev_100_dnaprom\n",
            "01/14/2026 06:25:27 - INFO - __main__ -   ***** Running prediction  *****\n",
            "01/14/2026 06:25:27 - INFO - __main__ -     Num examples = 100\n",
            "01/14/2026 06:25:27 - INFO - __main__ -     Batch size = 8\n",
            "Predicting: 100% 13/13 [00:00<00:00, 19.69it/s]\n",
            "\n",
            "==================================================\n",
            ">>> VERIFIKASI FILE HASIL\n",
            "==================================================\n",
            "âœ… SUKSES: File Attention ditemukan di: /content/DNABERT/examples/ft/my_binary_result/atten.npy\n",
            "âœ… SUKSES: File Prediksi ditemukan di: /content/DNABERT/examples/ft/my_binary_result/pred_results.npy\n",
            "ðŸ‘‰ Anda siap lanjut ke Tahap 7 (Motif Discovery).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ§¬ Run Motif Discovery (Fix Dependencies)\n",
        "#@markdown Script ini mencari pola DNA (motif) penting berdasarkan Attention Scores dari langkah prediksi.\n",
        "#@markdown\n",
        "#@markdown **Catatan:** Script ini otomatis menginstall library tambahan (`statsmodels`, `pyahocorasick`) yang dibutuhkan.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 2. Setup Path & Environment\n",
        "%cd /content/DNABERT/motif\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\"\n",
        "\n",
        "# Path Data & Hasil Prediksi (Konsisten dengan cell sebelumnya)\n",
        "data_dir = os.path.abspath(\"/content/DNABERT/examples/sample_data/my_binary_task\")\n",
        "predict_dir = os.path.abspath(\"/content/DNABERT/examples/ft/my_binary_result\")\n",
        "\n",
        "# Path Output Motif\n",
        "motif_dir = os.path.abspath(\"./found_motifs_result\")\n",
        "if not os.path.exists(motif_dir):\n",
        "    os.makedirs(motif_dir)\n",
        "\n",
        "# 3. Konfigurasi Parameter Motif\n",
        "# Jika menggunakan data dummy/sedikit, pval_cutoff 0.1 mungkin terlalu ketat.\n",
        "# Anda bisa mengubahnya ke 1.0 jika hasil output kosong.\n",
        "pval_cutoff = 0.1\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"ðŸ”Ž MOTIF DISCOVERY CONFIGURATION\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ðŸ”¹ Data Source   : {data_dir}\")\n",
        "print(f\"ðŸ”¹ Attention Src : {predict_dir}\")\n",
        "print(f\"ðŸ”¹ Output Dir    : {motif_dir}\")\n",
        "print(f\"ðŸ”¹ P-Value Cutoff: {pval_cutoff}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 4. Eksekusi Pencarian Motif\n",
        "print(\"\\n>>> Menjalankan algoritma pencarian motif...\")\n",
        "\n",
        "cmd = f\"\"\"\n",
        "{my_python} find_motifs.py \\\n",
        "    --data_dir \"{data_dir}\" \\\n",
        "    --predict_dir \"{predict_dir}\" \\\n",
        "    --window_size 24 \\\n",
        "    --min_len 5 \\\n",
        "    --pval_cutoff {pval_cutoff} \\\n",
        "    --min_n_motif 1 \\\n",
        "    --align_all_ties \\\n",
        "    --save_file_dir \"{motif_dir}\" \\\n",
        "    --verbose\n",
        "\"\"\"\n",
        "\n",
        "!{cmd}\n",
        "\n",
        "# 5. Cek Hasil\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "import glob\n",
        "files = glob.glob(f\"{motif_dir}/*.txt\")\n",
        "if len(files) > 0:\n",
        "    print(f\"âœ… SUKSES: Ditemukan {len(files)} motif.\")\n",
        "    print(f\"Cek folder: {motif_dir}\")\n",
        "else:\n",
        "    print(\"âš ï¸  HASIL KOSONG: Tidak ada motif yang lolos filter statistik.\")\n",
        "    print(\"Saran: Jika Anda menggunakan 'Dummy Data', coba ubah '--pval_cutoff 0.1' menjadi '1.0' di script di atas untuk melihat hasil tanpa filter.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "w43ZfaIvr4oA",
        "outputId": "d6c69219-922b-4712-ff38-227413a3441b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT/motif\n",
            "==================================================\n",
            "ðŸ”Ž MOTIF DISCOVERY CONFIGURATION\n",
            "==================================================\n",
            "ðŸ”¹ Data Source   : /content/DNABERT/examples/sample_data/my_binary_task\n",
            "ðŸ”¹ Attention Src : /content/DNABERT/examples/ft/my_binary_result\n",
            "ðŸ”¹ Output Dir    : /content/DNABERT/motif/found_motifs_result\n",
            "ðŸ”¹ P-Value Cutoff: 0.1\n",
            "==================================================\n",
            "\n",
            ">>> Menjalankan algoritma pencarian motif...\n",
            "*** Begin motif analysis ***\n",
            "* pos_seqs: 56; neg_seqs: 44\n",
            "* Finding high attention motif regions\n",
            "* Filtering motifs by hypergeometric test\n",
            "* Merging similar motif instances\n",
            "* Making fixed_length window = 24\n",
            "* Removing motifs with less than 1 instances\n",
            "* Saving outputs to directory\n",
            "\n",
            "==================================================\n",
            "âš ï¸  HASIL KOSONG: Tidak ada motif yang lolos filter statistik.\n",
            "Saran: Jika Anda menggunakan 'Dummy Data', coba ubah '--pval_cutoff 0.1' menjadi '1.0' di script di atas untuk melihat hasil tanpa filter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ”¬ Force Motif Output (Relaxed Mode)\n",
        "#@markdown ### Gunakan Cell ini jika Cell 7 kosong!\n",
        "#@markdown Jika Anda menggunakan **Dummy Data**, hampir pasti motif tidak akan lolos uji statistik (P-value < 0.05).\n",
        "#@markdown Cell ini mengubah `pval_cutoff` menjadi **1.0** (loloskan semua) agar Anda tetap bisa melihat hasil analisis pola DNA.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "\n",
        "# 1. Setup Path & Environment\n",
        "%cd /content/DNABERT/motif\n",
        "my_python = \"/usr/local/envs/myenv/bin/python\"\n",
        "\n",
        "data_dir = os.path.abspath(\"/content/DNABERT/examples/sample_data/my_binary_task\")\n",
        "predict_dir = os.path.abspath(\"/content/DNABERT/examples/ft/my_binary_result\")\n",
        "\n",
        "# Folder output khusus \"Relaxed\" agar tidak tercampur\n",
        "motif_dir = os.path.abspath(\"./found_motifs_result_relaxed\")\n",
        "\n",
        "if not os.path.exists(motif_dir):\n",
        "    os.makedirs(motif_dir)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"âš ï¸  FORCING MOTIF DISCOVERY (P-Value = 1.0)\")\n",
        "print(\"=\"*50)\n",
        "print(\"Tujuan: Melihat pola apa saja yang diperhatikan model,\")\n",
        "print(\"meskipun secara statistik belum tentu signifikan (karena data sedikit).\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 2. Jalankan Perintah (Relaxed)\n",
        "# Note: window_size 24 adalah default DNABERT\n",
        "cmd = f\"\"\"\n",
        "{my_python} find_motifs.py \\\n",
        "    --data_dir \"{data_dir}\" \\\n",
        "    --predict_dir \"{predict_dir}\" \\\n",
        "    --window_size 24 \\\n",
        "    --min_len 5 \\\n",
        "    --pval_cutoff 1.0 \\\n",
        "    --min_n_motif 1 \\\n",
        "    --align_all_ties \\\n",
        "    --save_file_dir \"{motif_dir}\" \\\n",
        "    --verbose\n",
        "\"\"\"\n",
        "\n",
        "# Menjalankan command\n",
        "# Kita mengabaikan error visualisasi (HTTP 308) karena kita hanya butuh file teksnya\n",
        "try:\n",
        "    !{cmd}\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 3. Cek & Baca Hasil\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\">>> ANALISIS HASIL (RELAXED)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "files = glob.glob(f\"{motif_dir}/*.txt\")\n",
        "\n",
        "if len(files) > 0:\n",
        "    print(f\"âœ… SUKSES: Ditemukan {len(files)} motif kandidat.\")\n",
        "    print(f\"ðŸ“ Lokasi: {motif_dir}\")\n",
        "\n",
        "    # Tampilkan isi file pertama sebagai contoh\n",
        "    sample_file = files[0]\n",
        "    print(f\"\\nðŸ“„ Contoh Isi File ({os.path.basename(sample_file)}):\")\n",
        "    print(\"-\" * 20)\n",
        "    with open(sample_file, 'r') as f:\n",
        "        # Baca 5 baris pertama saja agar tidak memenuhkan layar\n",
        "        print(\"\".join(f.readlines()[:10]))\n",
        "    print(\"...\")\n",
        "    print(\"-\" * 20)\n",
        "    print(\"ðŸ‘‰ Anda bisa lanjut ke Cell 9 untuk memvisualisasikan motif ini.\")\n",
        "else:\n",
        "    print(\"âŒ GAGAL: Masih tidak ada motif yang ditemukan.\")\n",
        "    print(\"Cek apakah file 'atten.npy' benar-benar ada di folder prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "bgTh1v_DDXG3",
        "outputId": "a7941bdb-dc5c-4b5c-e81e-e1fd97439256"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DNABERT/motif\n",
            "==================================================\n",
            "âš ï¸  FORCING MOTIF DISCOVERY (P-Value = 1.0)\n",
            "==================================================\n",
            "Tujuan: Melihat pola apa saja yang diperhatikan model,\n",
            "meskipun secara statistik belum tentu signifikan (karena data sedikit).\n",
            "--------------------------------------------------\n",
            "*** Begin motif analysis ***\n",
            "* pos_seqs: 56; neg_seqs: 44\n",
            "* Finding high attention motif regions\n",
            "* Filtering motifs by hypergeometric test\n",
            "* Merging similar motif instances\n",
            "* Making fixed_length window = 24\n",
            "* Removing motifs with less than 1 instances\n",
            "* Saving outputs to directory\n",
            "Traceback (most recent call last):\n",
            "  File \"find_motifs.py\", line 110, in <module>\n",
            "    main()\n",
            "  File \"find_motifs.py\", line 106, in main\n",
            "    return_idx  = args.return_idx\n",
            "  File \"/content/DNABERT/motif/motif_utils.py\", line 551, in motif_analysis\n",
            "    show_fineprint=False, show_ends=False, color_scheme='color_classic')\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/site-packages/Bio/motifs/__init__.py\", line 534, in weblogo\n",
            "    response = urlopen(req)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 532, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
            "    'http', request, response, code, msg, hdrs)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 570, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 308: Permanent Redirect\n",
            "\n",
            "==================================================\n",
            ">>> ANALISIS HASIL (RELAXED)\n",
            "==================================================\n",
            "âœ… SUKSES: Ditemukan 1 motif kandidat.\n",
            "ðŸ“ Lokasi: /content/DNABERT/motif/found_motifs_result_relaxed\n",
            "\n",
            "ðŸ“„ Contoh Isi File (motif_GTAGT_1.txt):\n",
            "--------------------\n",
            "ACGAACGTTGTTGTGCGGGCAACG\n",
            "\n",
            "...\n",
            "--------------------\n",
            "ðŸ‘‰ Anda bisa lanjut ke Cell 9 untuk memvisualisasikan motif ini.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ“Š Visualisasi Motif DNA (Final)\n",
        "#@markdown Script ini akan membaca file motif (.txt), mengubahnya menjadi matriks probabilitas, dan menggambar **Sequence Logo**.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "# 1. Install Library Logomaker (Silent Install)\n",
        "print(\">>> Memeriksa library Visualisasi...\")\n",
        "try:\n",
        "    import logomaker\n",
        "except ImportError:\n",
        "    print(\"   Menginstall logomaker (ini mungkin memakan waktu sebentar)...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"logomaker\"])\n",
        "    import logomaker\n",
        "print(\"âœ… Library siap.\")\n",
        "\n",
        "# 2. Tentukan Direktori Sumber (Auto-Switch)\n",
        "# Kita cek folder normal dulu, kalau kosong baru ke folder relaxed\n",
        "path_normal = os.path.abspath(\"/content/DNABERT/motif/found_motifs_result\")\n",
        "path_relaxed = os.path.abspath(\"/content/DNABERT/motif/found_motifs_result_relaxed\")\n",
        "\n",
        "target_dir = path_normal\n",
        "files = glob.glob(f\"{target_dir}/*.txt\")\n",
        "\n",
        "if len(files) == 0:\n",
        "    target_dir = path_relaxed\n",
        "    files = glob.glob(f\"{target_dir}/*.txt\")\n",
        "\n",
        "if len(files) == 0:\n",
        "    print(f\"âŒ GAGAL: Tidak ditemukan file motif (.txt) baik di '{path_normal}' maupun '{path_relaxed}'.\")\n",
        "    print(\"   Pastikan Anda sudah menjalankan Cell 7 atau Cell 8.\")\n",
        "else:\n",
        "    print(f\"âœ… SUMBER DATA: Ditemukan {len(files)} motif di folder: {os.path.basename(target_dir)}\")\n",
        "\n",
        "    # Batasi visualisasi maksimal 5 motif agar tidak terlalu banyak gambar\n",
        "    max_display = 5\n",
        "    files_to_process = files[:max_display]\n",
        "\n",
        "    for i, target_file in enumerate(files_to_process):\n",
        "        print(f\"\\nðŸŽ¨ [{i+1}/{len(files_to_process)}] Memproses: {os.path.basename(target_file)}\")\n",
        "\n",
        "        # 3. Baca Sequence\n",
        "        with open(target_file, \"r\") as f:\n",
        "            seqs = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        if not seqs:\n",
        "            print(\"   âš ï¸ File kosong, dilewati.\")\n",
        "            continue\n",
        "\n",
        "        # 4. Data Processing (Sequence -> Matrix)\n",
        "        # Kita asumsikan window size 24 (default DNABERT)\n",
        "        WINDOW_SIZE = 24\n",
        "        matrix_list = []\n",
        "        for seq in seqs:\n",
        "            if len(seq) == WINDOW_SIZE:\n",
        "                matrix_list.append(list(seq))\n",
        "\n",
        "        if len(matrix_list) > 0:\n",
        "            # Buat DataFrame hitungan\n",
        "            df = pd.DataFrame(matrix_list, columns=list(range(WINDOW_SIZE)))\n",
        "            counts_df = pd.DataFrame(index=df.columns, columns=['A', 'C', 'G', 'T']).fillna(0)\n",
        "\n",
        "            for col in df.columns:\n",
        "                val_counts = df[col].value_counts()\n",
        "                for base in ['A', 'C', 'G', 'T']:\n",
        "                    if base in val_counts:\n",
        "                        counts_df.loc[col, base] = val_counts[base]\n",
        "\n",
        "            # Transformasi ke Bits (Information Content)\n",
        "            info_mat = logomaker.transform_matrix(counts_df, from_type='counts', to_type='information')\n",
        "\n",
        "            # 5. Plotting\n",
        "            plt.figure(figsize=(10, 3))\n",
        "\n",
        "            # Style Logo\n",
        "            logo = logomaker.Logo(info_mat,\n",
        "                                 shade_below=.5,\n",
        "                                 fade_below=.5,\n",
        "                                 font_name='sans-serif') # Font aman\n",
        "\n",
        "            logo.style_spines(visible=False)\n",
        "            logo.style_spines(spines=['left', 'bottom'], visible=True)\n",
        "            logo.ax.set_ylabel('Bits', fontsize=10)\n",
        "            logo.ax.set_title(f\"Motif: {os.path.basename(target_file)}\", fontsize=12, fontweight='bold')\n",
        "\n",
        "            # Tampilkan label X axis setiap 5 posisi agar rapi\n",
        "            plt.xticks(range(0, WINDOW_SIZE, 5))\n",
        "\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"   âš ï¸ Panjang sequence tidak konsisten (bukan {WINDOW_SIZE}bp).\")\n",
        "\n",
        "    if len(files) > max_display:\n",
        "        print(f\"\\nâ„¹ï¸  ... dan {len(files) - max_display} motif lainnya tidak ditampilkan.\")\n",
        "\n",
        "print(\"\\nðŸ SELESAI. Pipeline Analisis Motif DNABERT telah rampung.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "cellView": "form",
        "collapsed": true,
        "id": "UKz2JXS49TZm",
        "outputId": "bd145d3e-d045-4ccc-d999-eacec87a0d42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Memeriksa library Visualisasi...\n",
            "   Menginstall logomaker (ini mungkin memakan waktu sebentar)...\n",
            "âœ… Library siap.\n",
            "âœ… SUMBER DATA: Ditemukan 1 motif di folder: found_motifs_result_relaxed\n",
            "\n",
            "ðŸŽ¨ [1/1] Memproses: motif_GTAGT_1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3951055419.py:65: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  counts_df = pd.DataFrame(index=df.columns, columns=['A', 'C', 'G', 'T']).fillna(0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x250 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ SELESAI. Pipeline Analisis Motif DNABERT telah rampung.\n"
          ]
        }
      ]
    }
  ]
}