{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "623ee232",
   "metadata": {},
   "source": [
    "# Stress Region Predictor: Mining & Retraining Pipeline\n",
    "\n",
    "This notebook handles the end-to-end process of creating a custom stress-response dataset and retraining the predictor models.\n",
    "\n",
    "**Pipeline Overview:**\n",
    "1. **Target Identification**: search NCBI for genes related to specific stress keywords (e.g., \"drought\", \"salt stress\").\n",
    "2. **Data Mining**: Download promoter/gene sequences for these targets and scan them for known PLACE motifs.\n",
    "3. **Model Training**: \n",
    "    - **ML Benchmark**: Compares SVM, Random Forest, etc., to find the best statistical model.\n",
    "    - **Deep Learning**: Fine-tunes PlantBERT on the new specific dataset.\n",
    "4. **Evaluation**: Ensembles the models and evaluates performance on a hold-out test set.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Target Identification (NCBI Search)\n",
    "*Searches the NCBI Gene database for Arabidopsis thaliana genes associated with stress keywords.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa13139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MEMULAI PENCARIAN GEN STRES (MODE AKSESI) ---\n",
      "\n",
      "[1/3] Mengirim request ke NCBI...\n",
      "      -> Ditemukan 2587 kandidat gen.\n",
      "[2/3] Memilah ID Aksesi (Locus Tag) yang valid...\n",
      "      -> Progress: 2585 ID valid terkumpul...\n",
      "      -> Selesai! 2585 ID siap pakai.\n",
      "\n",
      "[SUKSES] File tersimpan: list_gen_stres.txt\n",
      "Sekarang isi file ini adalah ID Locus Tag (misal: AT1G01010) yang pasti bisa didownload.\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "import time\n",
    "import re\n",
    "\n",
    "# =============================================================================\n",
    "# KONFIGURASI USER\n",
    "# =============================================================================\n",
    "Entrez.email = \"email_anda@example.com\"  # Ganti dengan email aktif\n",
    "organism = \"Arabidopsis thaliana\"\n",
    "\n",
    "# List keyword sama seperti sebelumnya\n",
    "stress_keywords = [\n",
    "    \"drought\", \"salt stress\", \"cold stress\", \"heat shock\", \n",
    "    \"abscisic acid\", \"water deprivation\", \"oxidative stress\", \"salinity\"\n",
    "]\n",
    "\n",
    "output_file = \"list_gen_stres.txt\"\n",
    "\n",
    "# =============================================================================\n",
    "# FUNGSI PENCARIAN & FILTER AKSESI\n",
    "# =============================================================================\n",
    "def fetch_gene_accessions():\n",
    "    print(f\"--- MEMULAI PENCARIAN GEN STRES (MODE AKSESI) ---\")\n",
    "    \n",
    "    # Query Search\n",
    "    term_query = f'\"{organism}\"[Orgn] AND ({ \" OR \".join(stress_keywords) })'\n",
    "    \n",
    "    # Regex untuk mendeteksi Locus Tag Arabidopsis (contoh: AT1G01010)\n",
    "    # AT = Arabidopsis, [1-5MC] = Kromosom 1-5/Mito/Chloro, G = Gen, \\d{5} = 5 digit angka\n",
    "    locus_tag_pattern = re.compile(r'AT[1-5MC]G\\d{5}', re.IGNORECASE)\n",
    "\n",
    "    try:\n",
    "        # 1. Search ke Database NCBI Gene\n",
    "        print(f\"\\n[1/3] Mengirim request ke NCBI...\")\n",
    "        search_handle = Entrez.esearch(db=\"gene\", term=term_query, retmax=10000, usehistory=\"y\")\n",
    "        search_results = Entrez.read(search_handle)\n",
    "        search_handle.close()\n",
    "        \n",
    "        count = int(search_results[\"Count\"])\n",
    "        webenv = search_results[\"WebEnv\"]\n",
    "        query_key = search_results[\"QueryKey\"]\n",
    "        \n",
    "        print(f\"      -> Ditemukan {count} kandidat gen.\")\n",
    "        \n",
    "        if count == 0:\n",
    "            return\n",
    "\n",
    "        # 2. Fetch Detail & Filter ID\n",
    "        print(f\"[2/3] Memilah ID Aksesi (Locus Tag) yang valid...\")\n",
    "        \n",
    "        valid_accessions = set()\n",
    "        batch_size = 300\n",
    "        \n",
    "        for start in range(0, count, batch_size):\n",
    "            fetch_handle = Entrez.esummary(\n",
    "                db=\"gene\", \n",
    "                retstart=start, \n",
    "                retmax=batch_size, \n",
    "                webenv=webenv, \n",
    "                query_key=query_key\n",
    "            )\n",
    "            data = Entrez.read(fetch_handle)\n",
    "            fetch_handle.close()\n",
    "            \n",
    "            for doc in data['DocumentSummarySet']['DocumentSummary']:\n",
    "                # Kumpulkan semua kemungkinan nama dari gen ini\n",
    "                potential_ids = []\n",
    "                \n",
    "                # 1. Cek Nama Utama\n",
    "                if 'Name' in doc: \n",
    "                    potential_ids.append(doc['Name'])\n",
    "                \n",
    "                # 2. Cek Nama Lain (OtherAliases) - biasanya Locus Tag sembunyi disini\n",
    "                if 'OtherAliases' in doc and doc['OtherAliases']:\n",
    "                    # OtherAliases formatnya string dipisah koma\n",
    "                    aliases = doc['OtherAliases'].split(',')\n",
    "                    potential_ids.extend([a.strip() for a in aliases])\n",
    "\n",
    "                # LOGIKA PEMILIHAN ID:\n",
    "                # Kita cari ID yang formatnya \"ATxGxxxxx\". Ini ID paling aman buat download.\n",
    "                selected_id = None\n",
    "                \n",
    "                for pid in potential_ids:\n",
    "                    if locus_tag_pattern.fullmatch(pid):\n",
    "                        selected_id = pid.upper()\n",
    "                        break # Ketemu Locus Tag! Stop cari.\n",
    "                \n",
    "                # Jika tidak ada Locus Tag, ambil Name biasa (cadangan)\n",
    "                if not selected_id and 'Name' in doc:\n",
    "                    selected_id = doc['Name']\n",
    "                \n",
    "                if selected_id:\n",
    "                    valid_accessions.add(selected_id)\n",
    "            \n",
    "            print(f\"      -> Progress: {len(valid_accessions)} ID valid terkumpul...\", end='\\r')\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        print(f\"\\n      -> Selesai! {len(valid_accessions)} ID siap pakai.\")\n",
    "\n",
    "        # 3. Simpan\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for acc in sorted(valid_accessions):\n",
    "                f.write(acc + \"\\n\")\n",
    "        \n",
    "        print(f\"\\n[SUKSES] File tersimpan: {output_file}\")\n",
    "        print(\"Sekarang isi file ini adalah ID Locus Tag (misal: AT1G01010) yang pasti bisa didownload.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR] {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_gene_accessions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c6d20",
   "metadata": {},
   "source": [
    "## 2. Sequence Mining & Motif Scanning\n",
    "*Downloads the specific sequences for the identified genes and scans them for motifs found in the PLACE database. This creates the \"Positive\" dataset (Label 1).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85a6365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1/3] Memuat Library Motif PLACE ---\n",
      "Total Motif Terpilih: 47\n",
      "\n",
      "--- [2/3] Memuat Daftar Target Gen ---\n",
      "--- [3/3] Mulai Mining (100 Gen) ---\n",
      "[1/100] AT1G01060: OK (2132bp). Scan... Found 27.\n",
      "[2/100] AT1G01140: OK (1838bp). Scan... Found 21.\n",
      "[3/100] AT1G01183: SKIP -> No mRNA found\n",
      "[4/100] AT1G01230: OK (876bp). Scan... Found 8.\n",
      "[5/100] AT1G01360: OK (1179bp). Scan... Found 5.\n",
      "[6/100] AT1G01470: OK (1348bp). Scan... Found 18.\n",
      "[7/100] AT1G01480: OK (2002bp). Scan... Found 18.\n",
      "[8/100] AT1G01510: OK (2637bp). Scan... Found 30.\n",
      "[9/100] AT1G01560: OK (1636bp). Scan... Found 23.\n",
      "[10/100] AT1G01620: OK (1549bp). Scan... Found 11.\n",
      "[11/100] AT1G01720: OK (1653bp). Scan... Found 27.\n",
      "[12/100] AT1G01790: OK (4237bp). Scan... Found 34.\n",
      "[13/100] AT1G02130: OK (1110bp). Scan... Found 15.\n",
      "[14/100] AT1G02205: OK (2705bp). Scan... Found 30.\n",
      "[15/100] AT1G02340: OK (1466bp). Scan... Found 7.\n",
      "[16/100] AT1G02500: OK (1748bp). Scan... Found 30.\n",
      "[17/100] AT1G02650: OK (1916bp). Scan... Found 27.\n",
      "[18/100] AT1G02730: OK (3925bp). Scan... Found 50.\n",
      "[19/100] AT1G02750: OK (1103bp). Scan... Found 8.\n",
      "[20/100] AT1G02813: OK (652bp). Scan... Found 5.\n",
      "[21/100] AT1G02816: OK (1602bp). Scan... Found 13.\n",
      "[22/100] AT1G02820: OK (816bp). Scan... Found 10.\n",
      "[23/100] AT1G02880: OK (1194bp). Scan... Found 8.\n",
      "[24/100] AT1G02900: OK (854bp). Scan... Found 5.\n",
      "[25/100] AT1G02920: OK (1213bp). Scan... Found 18.\n",
      "[26/100] AT1G02930: OK (1186bp). Scan... Found 15.\n",
      "[27/100] AT1G03060: OK (11892bp). Scan... Found 141.\n",
      "[28/100] AT1G03120: OK (648bp). Scan... Found 14.\n",
      "[29/100] AT1G03220: OK (1891bp). Scan... Found 29.\n",
      "[30/100] AT1G03230: OK (1870bp). Scan... Found 24.\n",
      "[31/100] AT1G03430: OK (1334bp). Scan... Found 13.\n",
      "[32/100] AT1G03680: OK (957bp). Scan... Found 7.\n",
      "[33/100] AT1G03770: OK (1473bp). Scan... Found 12.\n",
      "[34/100] AT1G03790: OK (1855bp). Scan... Found 19.\n",
      "[35/100] AT1G03870: OK (1164bp). Scan... Found 17.\n",
      "[36/100] AT1G03880: OK (1633bp). Scan... Found 21.\n",
      "[37/100] AT1G03980: OK (1596bp). Scan... Found 11.\n",
      "[38/100] AT1G04120: OK (5264bp). Scan... Found 47.\n",
      "[39/100] AT1G04220: OK (2044bp). Scan... Found 22.\n",
      "[40/100] AT1G04240: OK (1355bp). Scan... Found 11.\n",
      "[41/100] AT1G04400: OK (2422bp). Scan... Found 25.\n",
      "[42/100] AT1G04410: OK (1613bp). Scan... Found 27.\n",
      "[43/100] AT1G04520: OK (1569bp). Scan... Found 12.\n",
      "[44/100] AT1G04560: OK (855bp). Scan... Found 10.\n",
      "[45/100] AT1G04580: OK (4604bp). Scan... Found 54.\n",
      "[46/100] AT1G04880: OK (1767bp). Scan... Found 23.\n",
      "[47/100] AT1G05100: OK (1341bp). Scan... Found 25.\n",
      "[48/100] AT1G05180: OK (2044bp). Scan... Found 18.\n",
      "[49/100] AT1G05200: OK (3261bp). Scan... Found 26.\n",
      "[50/100] AT1G05240: OK (2478bp). Scan... Found 25.\n",
      "[51/100] AT1G05250: OK (1492bp). Scan... Found 12.\n",
      "[52/100] AT1G05260: OK (1254bp). Scan... Found 12.\n",
      "[53/100] AT1G05470: OK (3518bp). Scan... Found 31.\n",
      "[54/100] AT1G05510: OK (980bp). Scan... Found 12.\n",
      "[55/100] AT1G05520: OK (2944bp). Scan... Found 35.\n",
      "[56/100] AT1G05530: OK (1666bp). Scan... Found 25.\n",
      "[57/100] AT1G05560: OK (2136bp). Scan... Found 27.\n",
      "[58/100] AT1G05630: OK (3825bp). Scan... Found 33.\n",
      "[59/100] AT1G05680: OK (1755bp). Scan... Found 12.\n",
      "[60/100] AT1G05690: OK (1948bp). Scan... Found 15.\n",
      "[61/100] AT1G05850: OK (1905bp). Scan... Found 16.\n",
      "[62/100] AT1G06040: OK (1393bp). Scan... Found 17.\n",
      "[63/100] AT1G06390: OK (1590bp). Scan... Found 15.\n",
      "[64/100] AT1G06460: OK (1321bp). Scan... Found 10.\n",
      "[65/100] AT1G06770: OK (1970bp). Scan... Found 15.\n",
      "[66/100] AT1G07000: OK (2276bp). Scan... Found 27.\n",
      "[67/100] AT1G07200: OK (3898bp). Scan... Found 44.\n",
      "[68/100] AT1G07240: OK (1900bp). Scan... Found 27.\n",
      "[69/100] AT1G07350: OK (1860bp). Scan... Found 18.\n",
      "[70/100] AT1G07380: OK (2773bp). Scan... Found 17.\n",
      "[71/100] AT1G07400: OK (858bp). Scan... Found 18.\n",
      "[72/100] AT1G07430: OK (1906bp). Scan... Found 27.\n",
      "[73/100] AT1G07645: OK (676bp). Scan... Found 12.\n",
      "[74/100] AT1G07670: OK (3682bp). Scan... Found 34.\n",
      "[75/100] AT1G07720: OK (2098bp). Scan... Found 21.\n",
      "[76/100] AT1G07870: OK (1816bp). Scan... Found 23.\n",
      "[77/100] AT1G07890: OK (1297bp). Scan... Found 15.\n",
      "[78/100] AT1G07980: OK (1319bp). Scan... Found 9.\n",
      "[79/100] AT1G08380: OK (819bp). Scan... Found 9.\n",
      "[80/100] AT1G08430: OK (1961bp). Scan... Found 18.\n",
      "[81/100] AT1G08710: OK (1508bp). Scan... Found 10.\n",
      "[82/100] AT1G08720: OK (3260bp). Scan... Found 34.\n",
      "[83/100] AT1G08780: OK (724bp). Scan... Found 4.\n",
      "[84/100] AT1G08800: OK (4034bp). Scan... Found 33.\n",
      "[85/100] AT1G08810: OK (1317bp). Scan... Found 14.\n",
      "[86/100] AT1G08830: OK (873bp). Scan... Found 10.\n",
      "[87/100] AT1G08910: OK (2909bp). Scan... Found 31.\n",
      "[88/100] AT1G08920: OK (2041bp). Scan... Found 17.\n",
      "[89/100] AT1G08930: OK (2077bp). Scan... Found 18.\n",
      "[90/100] AT1G08970: OK (1216bp). Scan... Found 12.\n",
      "[91/100] AT1G09000: OK (1955bp). Scan... Found 22.\n",
      "[92/100] AT1G09080: OK (2095bp). Scan... Found 22.\n",
      "[93/100] AT1G09190: OK (1614bp). Scan... Found 10.\n",
      "[94/100] AT1G09210: OK (2201bp). Scan... Found 34.\n",
      "[95/100] AT1G09260: OK (440bp). Scan... Found 4.\n",
      "[96/100] AT1G09310: OK (989bp). Scan... Found 8.\n",
      "[97/100] AT1G09340: OK (2012bp). Scan... Found 18.\n",
      "[98/100] AT1G09350: OK (989bp). Scan... Found 9.\n",
      "[99/100] AT1G09530: OK (2143bp). Scan... Found 29.\n",
      "[100/100] AT1G09700: OK (1272bp). Scan... Found 4.\n",
      "\n",
      "[SELESAI] Data bersih tersimpan: Dataset_Fixed_Top100.csv\n",
      "Total Sequence: 1954\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NCBI MINER FINAL: FIX GIANT CHROMOSOME BUG\n",
    "# =============================================================================\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# =============================================================================\n",
    "# 1. KONFIGURASI\n",
    "# =============================================================================\n",
    "Entrez.email = \"plantbert_finetune@example.com\"\n",
    "\n",
    "# Filter Motif\n",
    "motif_filter_keywords = [\"ABRE\", \"DRE\", \"G-BOX\", \"MYB\", \"WRKY\", \"NAC\"]\n",
    "\n",
    "# Limit Gen (Bisa diisi angka atau None)\n",
    "LIMIT_GENES = 100 \n",
    "\n",
    "# PENTING: Batas Maksimal Panjang Sequence (agar tidak download kromosom)\n",
    "MAX_SEQ_LEN = 20000  # 20kb. Jika lebih dari ini, pasti salah download.\n",
    "\n",
    "# File Paths\n",
    "place_csv_path = '/Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/PLACE_Parsed_Complete_V2.csv'\n",
    "gene_list_path = 'list_gen_stres.txt' \n",
    "output_csv = f'Dataset_Fixed_Top{LIMIT_GENES}.csv'\n",
    "flank_bp = 50\n",
    "\n",
    "# =============================================================================\n",
    "# A. PERSIAPAN MOTIF\n",
    "# =============================================================================\n",
    "iu_map = {\n",
    "    'A': 'A', 'C': 'C', 'G': 'G', 'T': 'T', 'U': 'T',\n",
    "    'R': '[AG]', 'Y': '[CT]', 'M': '[AC]', 'K': '[GT]', 'S': '[GC]', 'W': '[AT]',\n",
    "    'H': '[ACT]', 'B': '[CGT]', 'V': '[ACG]', 'D': '[AGT]', 'N': '[ACGT]'\n",
    "}\n",
    "\n",
    "def iupac_to_regex_pattern(seq):\n",
    "    seq = str(seq).upper().strip()\n",
    "    seq = \"\".join([c for c in seq if c in iu_map]) \n",
    "    res = \"\"\n",
    "    for c in seq:\n",
    "        res += iu_map.get(c, c)\n",
    "    return res\n",
    "\n",
    "print(f\"--- [1/3] Memuat Library Motif PLACE ---\")\n",
    "motif_library = []\n",
    "\n",
    "if os.path.exists(place_csv_path):\n",
    "    df_place = pd.read_csv(place_csv_path)\n",
    "    col_seq = 'Sequence' if 'Sequence' in df_place.columns else df_place.columns[1]\n",
    "    col_id = 'ID' if 'ID' in df_place.columns else df_place.columns[0]\n",
    "\n",
    "    unique_motifs = df_place[[col_id, col_seq]].drop_duplicates()\n",
    "    \n",
    "    for idx, row in unique_motifs.iterrows():\n",
    "        m_id = str(row[col_id]).upper()\n",
    "        m_seq = row[col_seq]\n",
    "        \n",
    "        is_match = False\n",
    "        for k in motif_filter_keywords:\n",
    "            if k.upper() in m_id:\n",
    "                is_match = True\n",
    "                break\n",
    "        \n",
    "        if is_match and len(str(m_seq)) >= 3:\n",
    "            motif_library.append({\n",
    "                'id': row[col_id],\n",
    "                'original': m_seq,\n",
    "                'regex': re.compile(iupac_to_regex_pattern(m_seq))\n",
    "            })\n",
    "    print(f\"Total Motif Terpilih: {len(motif_library)}\")\n",
    "    if len(motif_library) == 0: exit()\n",
    "else:\n",
    "    print(\"Error: CSV tidak ditemukan.\")\n",
    "    exit()\n",
    "\n",
    "# =============================================================================\n",
    "# B. FUNGSI FETCH (LEBIH KETAT)\n",
    "# =============================================================================\n",
    "def fetch_sequence_strict(locus_tag):\n",
    "    try:\n",
    "        # PERBAIKAN 1: Tambah 'biomol_mrna[PROP]' agar tidak ambil kromosom\n",
    "        query = f\"{locus_tag}[Gene Name] AND Arabidopsis thaliana[Orgn] AND refseq[filter] AND biomol_mrna[PROP]\"\n",
    "        \n",
    "        handle = Entrez.esearch(db=\"nucleotide\", term=query, retmax=1)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        if not record['IdList']: return None, \"No mRNA found\"\n",
    "\n",
    "        seq_id = record['IdList'][0]\n",
    "        \n",
    "        with Entrez.efetch(db=\"nucleotide\", id=seq_id, rettype=\"fasta\", retmode=\"text\") as handle:\n",
    "            fasta_data = handle.read()\n",
    "        \n",
    "        lines = fasta_data.strip().split('\\n')\n",
    "        if not lines: return None, \"Empty FASTA\"\n",
    "        \n",
    "        full_seq = \"\".join(lines[1:]).upper()\n",
    "        \n",
    "        # PERBAIKAN 2: Cek Ukuran\n",
    "        if len(full_seq) > MAX_SEQ_LEN:\n",
    "            return None, f\"OVERSIZE ({len(full_seq)} bp) - Skipped\"\n",
    "            \n",
    "        return full_seq, \"Success\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "# =============================================================================\n",
    "# C. MAIN LOOP\n",
    "# =============================================================================\n",
    "print(\"\\n--- [2/3] Memuat Daftar Target Gen ---\")\n",
    "target_genes = []\n",
    "if os.path.exists(gene_list_path):\n",
    "    with open(gene_list_path, 'r') as f:\n",
    "        all_genes = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    if LIMIT_GENES and len(all_genes) > LIMIT_GENES:\n",
    "        target_genes = all_genes[:LIMIT_GENES]\n",
    "    else:\n",
    "        target_genes = all_genes\n",
    "else:\n",
    "    exit()\n",
    "\n",
    "print(f\"--- [3/3] Mulai Mining ({len(target_genes)} Gen) ---\")\n",
    "results = []\n",
    "batch_save = 10 \n",
    "\n",
    "for i, gid in enumerate(target_genes):\n",
    "    print(f\"[{i+1}/{len(target_genes)}] {gid}: \", end=\"\")\n",
    "    \n",
    "    # 1. Fetch Strict\n",
    "    seq, status = fetch_sequence_strict(gid)\n",
    "    \n",
    "    if seq:\n",
    "        print(f\"OK ({len(seq)}bp). Scan...\", end=\" \")\n",
    "        \n",
    "        hits = 0\n",
    "        for m in motif_library:\n",
    "            for match in m['regex'].finditer(seq):\n",
    "                start, end = match.start(), match.end()\n",
    "                \n",
    "                if start >= flank_bp and (end + flank_bp) <= len(seq):\n",
    "                    results.append({\n",
    "                        'Gene_Locus': gid,\n",
    "                        'Motif_ID': m['id'],\n",
    "                        'Motif_Pattern': m['original'],\n",
    "                        'Extracted_Sequence': seq[start-flank_bp : end+flank_bp],\n",
    "                        'Label': 1\n",
    "                    })\n",
    "                    hits += 1\n",
    "        print(f\"Found {hits}.\")\n",
    "    else:\n",
    "        # Print error merah/jelas jika oversize atau gagal\n",
    "        print(f\"SKIP -> {status}\")\n",
    "    \n",
    "    time.sleep(1.0) \n",
    "\n",
    "    if len(results) > 0 and i % batch_save == 0:\n",
    "        pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "\n",
    "if results:\n",
    "    final_df = pd.DataFrame(results).drop_duplicates(subset=['Extracted_Sequence'])\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n[SELESAI] Data bersih tersimpan: {output_csv}\")\n",
    "    print(f\"Total Sequence: {len(final_df)}\")\n",
    "else:\n",
    "    print(\"\\n[ZONK] Tidak ada data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc29c2",
   "metadata": {},
   "source": [
    "## 3. Model Retraining & Benchmarking\n",
    "*Trains a suite of machine learning models (SVM, RF, GB, LR) to find the best baseline, then fine-tunes the advanced PlantBERT model on the new data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b36b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Mined Dataset: Dataset_Fixed_Top100.csv\n",
      ">>> PART 1: Multi-Model ML Benchmark (Finding the Champion) <<<\n",
      "\n",
      "--- STARTING MULTI-MODEL ML TRAINING ---\n",
      "      -> Data split: 3126 Train, 782 Test\n",
      "      -> Feature Engineering (3-5 gram char vectorizer)...\n",
      "\n",
      "      -> Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Best Params: {'C': 0.1, 'solver': 'liblinear'}\n",
      "         Test Accuracy: 89.39% (1.8s)\n",
      "\n",
      "      -> Training RandomForest...\n",
      "         Best Params: {'max_depth': 20, 'n_estimators': 200}\n",
      "         Test Accuracy: 90.66% (8.6s)\n",
      "\n",
      "      -> Training SVM...\n",
      "         Best Params: {'C': 10, 'kernel': 'rbf'}\n",
      "         Test Accuracy: 93.48% (94.8s)\n",
      "\n",
      "      -> Training GradientBoosting...\n",
      "         Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "         Test Accuracy: 90.92% (13.0s)\n",
      "\n",
      "      --- MODEL LEADERBOARD ---\n",
      "             Model  Accuracy                                                 Best Params\n",
      "               SVM  0.934783                                  {'C': 10, 'kernel': 'rbf'}\n",
      "  GradientBoosting  0.909207 {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "      RandomForest  0.906650                      {'max_depth': 20, 'n_estimators': 200}\n",
      "LogisticRegression  0.893862                           {'C': 0.1, 'solver': 'liblinear'}\n",
      "\n",
      "      -> ðŸ† WINNER: SVM (Acc: 93.48%)\n",
      "      -> Saving winner to best_ml_model.pkl...\n",
      "\n",
      ">>> PART 2: Retraining PlantBERT Model (Deep Learning) <<<\n",
      "\n",
      "--- STARTING PLANTBERT RETRAINING ---\n",
      "      -> Data split: 3126 Train, 782 Test\n",
      "      -> Loading Tokenizer from: /Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/plantbert/PlantBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3126/3126 [00:00<00:00, 15859.88 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 782/782 [00:00<00:00, 26239.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -> Found potential checkpoint: /Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/plantbert/model_finetune_expanded/final\n",
      "      -> Loading Model Weights from: /Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/plantbert/model_finetune_expanded/final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/ensemble_predictor.py:419: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  print(f\"      -> Final Evaluation: {metrics}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -> Starting Training (this may take a while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/588 [00:00<?, ?it/s]/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "  2%|â–         | 10/588 [00:10<07:37,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.98, 'grad_norm': 20.17382049560547, 'learning_rate': 1.965986394557823e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 20/588 [00:18<08:15,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4326, 'grad_norm': 8.67276382446289, 'learning_rate': 1.9319727891156463e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 30/588 [00:27<08:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4216, 'grad_norm': 10.003146171569824, 'learning_rate': 1.8979591836734696e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 40/588 [00:35<06:57,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3159, 'grad_norm': 9.539231300354004, 'learning_rate': 1.863945578231293e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 50/588 [00:42<06:46,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3976, 'grad_norm': 7.323627471923828, 'learning_rate': 1.8299319727891158e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 60/588 [00:50<06:48,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3375, 'grad_norm': 4.703452110290527, 'learning_rate': 1.795918367346939e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 70/588 [00:58<06:38,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2871, 'grad_norm': 3.913191318511963, 'learning_rate': 1.761904761904762e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–Ž        | 80/588 [01:06<07:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3294, 'grad_norm': 13.498302459716797, 'learning_rate': 1.7278911564625852e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 90/588 [01:14<06:47,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.286, 'grad_norm': 9.126041412353516, 'learning_rate': 1.6938775510204085e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 100/588 [01:23<06:31,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2386, 'grad_norm': 9.362056732177734, 'learning_rate': 1.6598639455782314e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–Š        | 110/588 [01:30<06:04,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2891, 'grad_norm': 7.068602561950684, 'learning_rate': 1.6258503401360547e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 120/588 [01:38<06:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4499, 'grad_norm': 10.694055557250977, 'learning_rate': 1.5918367346938776e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 130/588 [01:47<07:01,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3087, 'grad_norm': 8.3496732711792, 'learning_rate': 1.557823129251701e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 140/588 [01:55<06:08,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3489, 'grad_norm': 11.42261791229248, 'learning_rate': 1.523809523809524e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 150/588 [02:03<05:28,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3247, 'grad_norm': 9.523676872253418, 'learning_rate': 1.4897959183673472e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 160/588 [02:11<05:24,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.322, 'grad_norm': 10.962268829345703, 'learning_rate': 1.4557823129251703e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 170/588 [02:19<05:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3303, 'grad_norm': 12.462139129638672, 'learning_rate': 1.4217687074829934e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 180/588 [02:26<05:04,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2065, 'grad_norm': 7.846676826477051, 'learning_rate': 1.3877551020408165e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 190/588 [02:33<04:53,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2532, 'grad_norm': 4.8294596672058105, 'learning_rate': 1.3537414965986395e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 196/588 [02:48<05:49,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25253772735595703, 'eval_accuracy': 0.9028132992327366, 'eval_runtime': 10.0766, 'eval_samples_per_second': 77.605, 'eval_steps_per_second': 4.863, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 200/588 [03:08<26:31,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2145, 'grad_norm': 5.751481056213379, 'learning_rate': 1.3197278911564626e-05, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 210/588 [05:48<2:24:03, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1222, 'grad_norm': 0.7764133214950562, 'learning_rate': 1.2857142857142859e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 220/588 [06:59<41:41,  6.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0879, 'grad_norm': 4.708647727966309, 'learning_rate': 1.251700680272109e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 230/588 [07:59<31:53,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.18, 'grad_norm': 2.9907782077789307, 'learning_rate': 1.217687074829932e-05, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 240/588 [08:57<27:43,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0807, 'grad_norm': 16.218059539794922, 'learning_rate': 1.1836734693877552e-05, 'epoch': 1.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 250/588 [09:57<33:05,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1808, 'grad_norm': 5.034151077270508, 'learning_rate': 1.1496598639455783e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 260/588 [11:00<34:42,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1813, 'grad_norm': 1.49099600315094, 'learning_rate': 1.1156462585034013e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 270/588 [11:55<30:14,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1836, 'grad_norm': 12.38576889038086, 'learning_rate': 1.0816326530612246e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 280/588 [12:52<20:10,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1316, 'grad_norm': 15.145120620727539, 'learning_rate': 1.0476190476190477e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 290/588 [13:31<09:56,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1041, 'grad_norm': 13.19168758392334, 'learning_rate': 1.0136054421768708e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 300/588 [13:39<03:52,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2811, 'grad_norm': 16.65955924987793, 'learning_rate': 9.795918367346939e-06, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 310/588 [13:47<03:33,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1507, 'grad_norm': 18.326519012451172, 'learning_rate': 9.455782312925171e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 320/588 [13:55<03:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1509, 'grad_norm': 15.6341552734375, 'learning_rate': 9.115646258503402e-06, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 330/588 [14:03<03:19,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1591, 'grad_norm': 14.857186317443848, 'learning_rate': 8.775510204081633e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 340/588 [14:11<03:18,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0903, 'grad_norm': 0.6768525242805481, 'learning_rate': 8.435374149659866e-06, 'epoch': 1.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 350/588 [14:18<03:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1204, 'grad_norm': 14.961328506469727, 'learning_rate': 8.095238095238097e-06, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 360/588 [14:26<02:55,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0816, 'grad_norm': 12.523082733154297, 'learning_rate': 7.755102040816327e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 370/588 [14:34<02:49,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1596, 'grad_norm': 29.433759689331055, 'learning_rate': 7.414965986394559e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 380/588 [14:41<02:33,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0529, 'grad_norm': 0.8441950678825378, 'learning_rate': 7.07482993197279e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 390/588 [14:49<02:27,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2505, 'grad_norm': 25.59351921081543, 'learning_rate': 6.734693877551021e-06, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 392/588 [15:00<02:05,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3259139358997345, 'eval_accuracy': 0.9130434782608695, 'eval_runtime': 9.8084, 'eval_samples_per_second': 79.728, 'eval_steps_per_second': 4.996, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 400/588 [15:10<03:25,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0495, 'grad_norm': 0.34349802136421204, 'learning_rate': 6.394557823129253e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 410/588 [15:18<02:13,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0852, 'grad_norm': 38.74953079223633, 'learning_rate': 6.054421768707484e-06, 'epoch': 2.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 420/588 [15:25<02:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1315, 'grad_norm': 16.984073638916016, 'learning_rate': 5.7142857142857145e-06, 'epoch': 2.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 430/588 [15:33<01:57,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0715, 'grad_norm': 21.246265411376953, 'learning_rate': 5.374149659863946e-06, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 440/588 [15:40<01:51,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0668, 'grad_norm': 2.8187973499298096, 'learning_rate': 5.034013605442177e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 450/588 [15:48<01:41,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0554, 'grad_norm': 4.509387969970703, 'learning_rate': 4.693877551020409e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 460/588 [15:55<01:33,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1568, 'grad_norm': 22.039386749267578, 'learning_rate': 4.35374149659864e-06, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 470/588 [16:03<01:26,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1092, 'grad_norm': 6.196048736572266, 'learning_rate': 4.013605442176871e-06, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 480/588 [16:10<01:22,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0828, 'grad_norm': 0.7279826998710632, 'learning_rate': 3.6734693877551024e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 490/588 [16:18<01:12,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0518, 'grad_norm': 0.10322180390357971, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 500/588 [16:25<01:04,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0754, 'grad_norm': 2.7487616539001465, 'learning_rate': 2.993197278911565e-06, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 510/588 [16:32<00:57,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0132, 'grad_norm': 1.2769514322280884, 'learning_rate': 2.6530612244897964e-06, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 520/588 [16:40<00:49,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0529, 'grad_norm': 1.9522881507873535, 'learning_rate': 2.3129251700680273e-06, 'epoch': 2.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 530/588 [16:47<00:42,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0396, 'grad_norm': 0.16937749087810516, 'learning_rate': 1.9727891156462586e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 540/588 [16:55<00:35,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0319, 'grad_norm': 5.8034796714782715, 'learning_rate': 1.6326530612244897e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 550/588 [17:02<00:27,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0753, 'grad_norm': 0.12378685921430588, 'learning_rate': 1.2925170068027212e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 560/588 [17:10<00:20,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0883, 'grad_norm': 10.11269474029541, 'learning_rate': 9.523809523809525e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 570/588 [17:17<00:13,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0498, 'grad_norm': 0.2633243501186371, 'learning_rate': 6.122448979591837e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 580/588 [17:24<00:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0367, 'grad_norm': 22.25841522216797, 'learning_rate': 2.72108843537415e-07, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588/588 [17:30<00:00,  1.58it/s]/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                 \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588/588 [17:43<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29973772168159485, 'eval_accuracy': 0.928388746803069, 'eval_runtime': 9.6649, 'eval_samples_per_second': 80.912, 'eval_steps_per_second': 5.07, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 588/588 [17:46<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1066.4909, 'train_samples_per_second': 8.793, 'train_steps_per_second': 0.551, 'train_loss': 0.1897736503837668, 'epoch': 3.0}\n",
      "      -> Saving PlantBERT to /Users/user/Downloads/02. PROJECTS/Stress-region-predictor/train/plantbert/model_finetune_expanded/plantbert_finetuned_mined/final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/promac/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:09<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -> Final Evaluation: {'eval_loss': 0.29973772168159485, 'eval_accuracy': 0.928388746803069, 'eval_runtime': 9.7041, 'eval_samples_per_second': 80.584, 'eval_steps_per_second': 5.049, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RETRAINING STAGE: TRAIN ALL MODELS (ML BENCHMARK + PLANTBERT)\n",
    "# =============================================================================\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# 1. ADD MODULE PATH\n",
    "project_root = \"/Users/user/Downloads/02. PROJECTS/Stress-region-predictor\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# 2. FORCE RELOAD & IMPORT FUNCTIONS\n",
    "# Ideally, you should restart the kernel if code changes significantly, \n",
    "# but this helps picking up new functions on the fly.\n",
    "import train.ensemble_predictor\n",
    "importlib.reload(train.ensemble_predictor)\n",
    "from train.ensemble_predictor import train_multimodel_ml, train_plantbert_from_mined_data\n",
    "\n",
    "# 3. DEFINE INPUT\n",
    "try:\n",
    "    # Use variable from previous cell if available\n",
    "    mined_csv = output_csv\n",
    "except NameError:\n",
    "    # Fallback default\n",
    "    mined_csv = \"Dataset_Fixed_Top100.csv\"\n",
    "\n",
    "print(f\"Using Mined Dataset: {mined_csv}\")\n",
    "\n",
    "# 4. TRAIN MODELS\n",
    "print(\">>> PART 1: Multi-Model ML Benchmark (Finding the Champion) <<<\")\n",
    "# This will run SVM, RandomForest, GradientBoosting, and LogisticRegression\n",
    "# It selects the BEST one automatically.\n",
    "best_ml_model, vectorizer = train_multimodel_ml(mined_csv)\n",
    "\n",
    "print(\"\\n>>> PART 2: Retraining PlantBERT Model (Deep Learning) <<<\")\n",
    "# This trains the heavy transformer model\n",
    "plantbert_model, bert_tokenizer = train_plantbert_from_mined_data(mined_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b37547",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Deployment\n",
    "*Runs the final ensemble model on a hold-out test set to calculate accuracy and classification metrics, then saves the optimal models for future use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e464388c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Calculating Accuracy on Test Set...\n",
      "\n",
      "--- EVALUATING MODEL ACCURACY ON TEST SET (20% Hold-out) ---\n",
      "   -> ML Model Accuracy: 94.76%\n",
      "   -> Evaluating PlantBERT (this takes a moment)...\n",
      "   -> PlantBERT Accuracy: 92.71%\n",
      "\n",
      "--- RUNNING FINAL ENSEMBLE PREDICTION ---\n",
      "      -> getting ML probabilities...\n",
      "      -> getting PlantBERT probabilities...\n",
      "      -> Saved to Final_Ensemble_Predictions.csv\n",
      "\n",
      "--- SAVING MODELS ---\n",
      "   -> ML Model saved to: final_best_ml_model.pkl\n",
      "   -> PlantBERT saved to: final_plantbert_model/\n",
      "\n",
      "--- TOP HIGH CONFIDENCE PREDICTIONS ---\n",
      "     Gene_Locus         Motif_ID  ML_Prob  BERT_Prob  Stress_Probability\n",
      "345   AT1G02730          MYBCORE      1.0     0.9997              0.9999\n",
      "1602  AT1G08430          AMYBOX2      1.0     0.9997              0.9999\n",
      "842   AT1G04410  MYB2CONSENSUSAT      1.0     0.9997              0.9999\n",
      "1677  AT1G08800          MYBCORE      1.0     0.9997              0.9999\n",
      "571   AT1G03060         WRKY71OS      1.0     0.9997              0.9999\n",
      "371   AT1G02750          MYBCORE      1.0     0.9997              0.9999\n",
      "1468  AT1G07430           MYBST1      1.0     0.9996              0.9998\n",
      "536   AT1G03060         WRKY71OS      1.0     0.9996              0.9998\n",
      "572   AT1G03060         WRKY71OS      1.0     0.9996              0.9998\n",
      "1424  AT1G07380         WRKY71OS      1.0     0.9997              0.9998\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL STEP: PREDICT & SAVE YOUR NEW MODELS\n",
    "# =============================================================================\n",
    "import joblib\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# 1. RELOAD MODULE TO CATCH UPDATES\n",
    "# This fixes the ImportError by forcing Python to look at the updated file\n",
    "import train.ensemble_predictor\n",
    "importlib.reload(train.ensemble_predictor)\n",
    "from train.ensemble_predictor import predict_with_new_models, evaluate_models_on_holdout\n",
    "\n",
    "# 2. RUN & SAVE\n",
    "if 'best_ml_model' in locals() and 'plantbert_model' in locals():\n",
    "    # A. Get Accuracy Summary (New Feature)\n",
    "    print(\"\\n[INFO] Calculating Accuracy on Test Set...\")\n",
    "    metrics = evaluate_models_on_holdout(\n",
    "        mined_csv, \n",
    "        svm_model=best_ml_model, \n",
    "        vectorizer=vectorizer, \n",
    "        bert_model=plantbert_model, \n",
    "        bert_tokenizer=bert_tokenizer\n",
    "    )\n",
    "\n",
    "    # B. Run Prediction\n",
    "    df_results = predict_with_new_models(\n",
    "        mined_csv, \n",
    "        svm_model=best_ml_model, \n",
    "        vectorizer=vectorizer, \n",
    "        bert_model=plantbert_model, \n",
    "        bert_tokenizer=bert_tokenizer\n",
    "    )\n",
    "    \n",
    "    # C. Save Models to Disk for Future Use\n",
    "    print(\"\\n--- SAVING MODELS ---\")\n",
    "    \n",
    "    # Save ML Model (e.g. SVM/RF)\n",
    "    ml_path = \"final_best_ml_model.pkl\"\n",
    "    joblib.dump(best_ml_model, ml_path)\n",
    "    joblib.dump(vectorizer, ml_path.replace(\".pkl\", \"_vectorizer.pkl\"))\n",
    "    print(f\"   -> ML Model saved to: {ml_path}\")\n",
    "    \n",
    "    # Save PlantBERT (Deep Learning)\n",
    "    bert_path = \"final_plantbert_model\"\n",
    "    plantbert_model.save_pretrained(bert_path)\n",
    "    bert_tokenizer.save_pretrained(bert_path)\n",
    "    print(f\"   -> PlantBERT saved to: {bert_path}/\")\n",
    "\n",
    "    # D. Show Top Hits\n",
    "    if df_results is not None:\n",
    "        print(\"\\n--- TOP HIGH CONFIDENCE PREDICTIONS ---\")\n",
    "        print(df_results.sort_values(by=\"Stress_Probability\", ascending=False).head(10)[['Gene_Locus', 'Motif_ID', 'ML_Prob', 'BERT_Prob', 'Stress_Probability']])\n",
    "else:\n",
    "    print(\"Please run the training cell above first!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
