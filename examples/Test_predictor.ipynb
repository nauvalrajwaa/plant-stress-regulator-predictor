{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nauvalrajwaa/plant-stress-regulator-predictor.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGz5A3vXekQD",
        "outputId": "4c937c50-45f1-43ee-e629-9f327b623b30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'plant-stress-regulator-predictor' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7m45WY2i6-I",
        "outputId": "88e7e773-b24d-4db5-c5a7-d558dd329fc1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at b4d3fa4 add new models\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/plant-stress-regulator-predictor\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Aqr8ZSu_exze",
        "outputId": "68378a48-253c-4f0e-a435-7724d1f89f47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plant-stress-regulator-predictor\n",
            "Collecting transformers==4.47.0 (from -r requirements.txt (line 1))\n",
            "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: logomaker in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.8.7)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (0.4.6)\n",
            "Requirement already satisfied: peft>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.18.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (2.32.4)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.47.0->-r requirements.txt (line 1))\n",
            "  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->-r requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 12)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 12)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 12)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0->-r requirements.txt (line 1)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->-r requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 12)) (1.22.0)\n",
            "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
            "Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.4\n",
            "    Uninstalling transformers-4.57.4:\n",
            "      Successfully uninstalled transformers-4.57.4\n",
            "Successfully installed tokenizers-0.21.4 transformers-4.47.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade peft accelerate transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgxxISgDffSq",
        "outputId": "08bc082f-c5ba-40c7-d533-3ba3de0eb503"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.47.0)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.57.4-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Using cached transformers-4.57.4-py3-none-any.whl (12.0 MB)\n",
            "Using cached tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.0\n",
            "    Uninstalling transformers-4.47.0:\n",
            "      Successfully uninstalled transformers-4.47.0\n",
            "Successfully installed tokenizers-0.22.2 transformers-4.57.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/plant-stress-regulator-predictor\n",
        "!python scripts/train.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xFt218LTe-K3",
        "outputId": "9993e283-ba7c-4409-e37e-fe468de07ecd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plant-stress-regulator-predictor\n",
            "2026-01-13 13:16:32.814585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768310192.833949    1526 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768310192.839793    1526 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768310192.854544    1526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768310192.854570    1526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768310192.854574    1526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768310192.854577    1526 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-13 13:16:32.859020: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: train.py [-h] [--step {all,search,mine,train,eval}] [--email EMAIL]\n",
            "                [--task-type {binary,multiclass}] [--organism ORGANISM]\n",
            "                [--max-seq-len MAX_SEQ_LEN] [--flank-bp FLANK_BP]\n",
            "                [--gene-list GENE_LIST] [--place-csv PLACE_CSV]\n",
            "                [--mined-data MINED_DATA] [--limit-genes LIMIT_GENES]\n",
            "                [--logo-out LOGO_OUT] [--save-models] [--no-save-models]\n",
            "                [--model-path MODEL_PATH]\n",
            "                [--llm-model {plantbert,dnabert2,custom}]\n",
            "\n",
            "Stress Region Predictor Training Pipeline\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --step {all,search,mine,train,eval}\n",
            "                        Pipeline step to run (default: all)\n",
            "  --email EMAIL         NCBI Email (default: user@example.com)\n",
            "  --task-type {binary,multiclass}\n",
            "                        Classification type (default: binary)\n",
            "  --organism ORGANISM   Target Organism (e.g. 'Oryza sativa') (default:\n",
            "                        Arabidopsis thaliana)\n",
            "  --max-seq-len MAX_SEQ_LEN\n",
            "                        Maximum sequence length to download (default: 20000)\n",
            "  --flank-bp FLANK_BP   Flanking base pairs around motif (default: 50)\n",
            "  --gene-list GENE_LIST\n",
            "                        Path to gene list file (Auto-generated if None)\n",
            "                        (default: None)\n",
            "  --place-csv PLACE_CSV\n",
            "                        Path to PLACE motif CSV (Auto-detected if None)\n",
            "                        (default: None)\n",
            "  --mined-data MINED_DATA\n",
            "                        Path to output mined CSV (Auto-generated if None)\n",
            "                        (default: None)\n",
            "  --limit-genes LIMIT_GENES\n",
            "                        Limit number of genes to mine (0 = No limit) (default:\n",
            "                        100)\n",
            "  --logo-out LOGO_OUT   Output directory for Logo plots (default: None)\n",
            "  --save-models         Save trained models (default: True) (default: True)\n",
            "  --no-save-models      Disable model saving (default: True)\n",
            "  --model-path MODEL_PATH\n",
            "                        Path to base model (PlantBERT or DNABERT, local or HF\n",
            "                        ID) (default: None)\n",
            "  --llm-model {plantbert,dnabert2,custom}\n",
            "                        Select LLM preset: 'plantbert' (nigelhartm/PlantBERT)\n",
            "                        or 'dnabert2' (zhihan1996/DNABERT-2-117M) (default:\n",
            "                        plantbert)\n",
            "\n",
            "Examples: 1. Full pipeline (Search -> Mine -> Train): python scripts/train.py\n",
            "--step all --email user@example.com 2. Mining only (with custom organism and\n",
            "size): python scripts/train.py --step mine --organism \"Oryza sativa\" --limit-\n",
            "genes 500 3. Multiclass Training: python scripts/train.py --step train --task-\n",
            "type multiclass --mined-data \"My_Rice_Data.csv\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers accelerate peft einops\n",
        "# Restart Runtime: Runtime > Restart Session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2XQHClm2iTb5",
        "outputId": "584af3b8-36ae-4cec-bc63-f31131e0bca0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.4\n",
            "    Uninstalling transformers-4.57.4:\n",
            "      Successfully uninstalled transformers-4.57.4\n",
            "Successfully installed transformers-4.57.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone triton\n",
        "%cd /content/\n",
        "\n",
        "!git clone https://github.com/openai/triton.git /content/triton\n",
        "%cd /content/triton/python/\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/triton\n",
        "!git checkout 239f920c\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I2hr4tm_oyJA",
        "outputId": "ab900e71-0887-46d3-cfd6-160ed9c81f43"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/content/triton'...\n",
            "remote: Enumerating objects: 236569, done.\u001b[K\n",
            "remote: Counting objects: 100% (520/520), done.\u001b[K\n",
            "remote: Compressing objects: 100% (308/308), done.\u001b[K\n",
            "remote: Total 236569 (delta 335), reused 214 (delta 212), pack-reused 236049 (from 3)\u001b[K\n",
            "Receiving objects: 100% (236569/236569), 599.29 MiB | 15.57 MiB/s, done.\n",
            "Resolving deltas: 100% (164101/164101), done.\n",
            "/content/triton/python\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.45.1)\n",
            "Requirement already satisfied: cmake<4.0,>=3.20 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (3.31.10)\n",
            "Collecting ninja>=1.11.1 (from -r requirements.txt (line 4))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybind11>=2.13.1 (from -r requirements.txt (line 5))\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting lit (from -r requirements.txt (line 6))\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, pybind11, ninja\n",
            "Successfully installed lit-18.1.8 ninja-1.13.0 pybind11-3.0.1\n",
            "/content/triton\n",
            "Note: switching to '239f920c'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 239f920c1 Add mask to tl.device_assert (#7905)\n",
            "Obtaining file:///content/triton\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton==3.4.0+git239f920c) (75.2.0)\n",
            "Building wheels for collected packages: triton\n",
            "  Building editable for triton (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 423, in run\n",
            "    _, build_failures = build(\n",
            "                        ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 319, in build\n",
            "    wheel_file = _build_one(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 193, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 226, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_editable(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/build/wheel_editable.py\", line 31, in build_wheel_editable\n",
            "    wheel_name = backend.build_editable(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/misc.py\", line 701, in build_editable\n",
            "    return super().build_editable(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 270, in build_editable\n",
            "    return self._call_hook('build_editable', {\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 311, in _call_hook\n",
            "    self._subprocess_runner(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 237, in runner\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1164, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1144, in flush\n",
            "    self.stream.flush()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/plant-stress-regulator-predictor\n",
        "!python scripts/train.py --organism \"Nicotiana tabacum\" --llm-model plantbert --limit-genes 150"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlHPMYBngIuy",
        "outputId": "7b9ad1ff-fdcd-452f-aba7-629c69f3c025"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/plant-stress-regulator-predictor\n",
            "2026-01-13 14:39:59.100411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768315199.126633   23181 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768315199.134789   23181 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768315199.164126   23181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768315199.164153   23181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768315199.164157   23181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768315199.164160   23181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-13 14:39:59.168940: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "--- RUN CONFIGURATION ---\n",
            "Run ID: run_20260113_144012_Nicotiana_tabacum_plantbert\n",
            "Run Directory: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert\n",
            "Gene List: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/data/list_gen_Nicotiana_tabacum_150_20000.txt\n",
            "Mined Sequence Data: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/data/dataset_Nicotiana_tabacum_150_20000.csv\n",
            "Models Directory: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models\n",
            "Base Model Path: nigelhartm/PlantBERT\n",
            "-------------------------\n",
            "--- STEP 1: SEARCH NCBI DATABASE ---\n",
            "[1/3] Attempting search in 'gene' database...\n",
            "      -> Found 850 candidates in Gene DB.\n",
            "      -> Progress: 850 IDs...\n",
            "      -> Finished! 850 IDs ready.\n",
            "\n",
            "[SUCCESS] Saved to: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/data/list_gen_Nicotiana_tabacum_150_20000.txt\n",
            "\n",
            "--- STEP 2: MINING SEQUENCES ---\n",
            "Config: Organism=Nicotiana tabacum, MaxSeqLen=20000, FlankBP=50, Mode=binary\n",
            "[1/3] Loading PLACE Motif Library from /content/plant-stress-regulator-predictor/train_1/data/PLACE_Parsed_Complete_V2.csv...\n",
            "      -> Selected 47 motifs.\n",
            "[2/3] Loading Target Genes from /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/data/list_gen_Nicotiana_tabacum_150_20000.txt\n",
            "[3/3] Mining 150 genes...\n",
            "[1/150] LOC107758922: SKIP -> Not found\n",
            "[2/150] LOC107758994: OK (1407bp). Scan... Found 11.\n",
            "[3/150] LOC107759348: OK (1282bp). Scan... Found 17.\n",
            "[4/150] LOC107759554: OK (1386bp). Scan... Found 16.\n",
            "[5/150] LOC107759703: OK (1055bp). Scan... Found 11.\n",
            "[6/150] LOC107759771: OK (1163bp). Scan... Found 24.\n",
            "[7/150] LOC107759988: OK (1133bp). Scan... Found 4.\n",
            "[8/150] LOC107759990: OK (1467bp). Scan... Found 14.\n",
            "[9/150] LOC107759994: OK (1895bp). Scan... Found 23.\n",
            "[10/150] LOC107760113: OK (1219bp). Scan... Found 10.\n",
            "[11/150] LOC107760279: OK (1329bp). Scan... Found 8.\n",
            "[12/150] LOC107760324: OK (1047bp). Scan... Found 8.\n",
            "[13/150] LOC107760333: OK (791bp). Scan... Found 4.\n",
            "[14/150] LOC107760423: OK (1805bp). Scan... Found 10.\n",
            "[15/150] LOC107760428: OK (920bp). Scan... Found 8.\n",
            "[16/150] LOC107760429: OK (1000bp). Scan... Found 10.\n",
            "[17/150] LOC107760472: OK (795bp). Scan... Found 3.\n",
            "[18/150] LOC107760487: OK (1073bp). Scan... Found 7.\n",
            "[19/150] LOC107760703: OK (2322bp). Scan... Found 21.\n",
            "[20/150] LOC107760739: OK (2089bp). Scan... Found 16.\n",
            "[21/150] LOC107760781: OK (1353bp). Scan... Found 15.\n",
            "[22/150] LOC107761056: OK (685bp). Scan... Found 5.\n",
            "[23/150] LOC107761076: OK (1231bp). Scan... Found 6.\n",
            "[24/150] LOC107761108: OK (1098bp). Scan... Found 2.\n",
            "[25/150] LOC107761161: OK (631bp). Scan... Found 2.\n",
            "[26/150] LOC107761201: OK (1340bp). Scan... Found 6.\n",
            "[27/150] LOC107761202: OK (1444bp). Scan... Found 10.\n",
            "[28/150] LOC107761204: OK (1156bp). Scan... Found 8.\n",
            "[29/150] LOC107761232: OK (1047bp). Scan... Found 14.\n",
            "[30/150] LOC107761316: OK (1412bp). Scan... Found 5.\n",
            "[31/150] LOC107761359: OK (1308bp). Scan... Found 15.\n",
            "[32/150] LOC107761847: OK (3010bp). Scan... Found 27.\n",
            "[33/150] LOC107762094: OK (978bp). Scan... Found 5.\n",
            "[34/150] LOC107762405: OK (1276bp). Scan... Found 23.\n",
            "[35/150] LOC107762416: OK (938bp). Scan... Found 19.\n",
            "[36/150] LOC107762521: OK (2490bp). Scan... Found 28.\n",
            "[37/150] LOC107762601: OK (900bp). Scan... Found 9.\n",
            "[38/150] LOC107762606: OK (1123bp). Scan... Found 13.\n",
            "[39/150] LOC107762615: OK (1213bp). Scan... Found 10.\n",
            "[40/150] LOC107762653: OK (797bp). Scan... Found 10.\n",
            "[41/150] LOC107762686: SKIP -> Not found\n",
            "[42/150] LOC107762727: OK (1083bp). Scan... Found 7.\n",
            "[43/150] LOC107762756: OK (1414bp). Scan... Found 14.\n",
            "[44/150] LOC107762871: OK (1754bp). Scan... Found 21.\n",
            "[45/150] LOC107763065: OK (800bp). Scan... Found 2.\n",
            "[46/150] LOC107763189: OK (1072bp). Scan... Found 14.\n",
            "[47/150] LOC107763249: OK (1013bp). Scan... Found 7.\n",
            "[48/150] LOC107763252: OK (860bp). Scan... Found 4.\n",
            "[49/150] LOC107763284: OK (1653bp). Scan... Found 10.\n",
            "[50/150] LOC107763333: OK (605bp). Scan... Found 2.\n",
            "[51/150] LOC107763371: OK (1217bp). Scan... Found 13.\n",
            "[52/150] LOC107763461: OK (1280bp). Scan... Found 14.\n",
            "[53/150] LOC107763677: OK (710bp). Scan... Found 2.\n",
            "[54/150] LOC107763885: OK (934bp). Scan... Found 9.\n",
            "[55/150] LOC107763907: OK (766bp). Scan... Found 8.\n",
            "[56/150] LOC107763942: SKIP -> Not found\n",
            "[57/150] LOC107763949: OK (2579bp). Scan... Found 34.\n",
            "[58/150] LOC107764249: OK (462bp). Scan... Found 5.\n",
            "[59/150] LOC107764271: OK (742bp). Scan... Found 5.\n",
            "[60/150] LOC107764273: SKIP -> Not found\n",
            "[61/150] LOC107764368: SKIP -> Not found\n",
            "[62/150] LOC107764552: OK (1073bp). Scan... Found 10.\n",
            "[63/150] LOC107764596: OK (890bp). Scan... Found 16.\n",
            "[64/150] LOC107764730: OK (647bp). Scan... Found 4.\n",
            "[65/150] LOC107764746: OK (1389bp). Scan... Found 9.\n",
            "[66/150] LOC107764881: OK (1768bp). Scan... Found 17.\n",
            "[67/150] LOC107764955: OK (2458bp). Scan... Found 36.\n",
            "[68/150] LOC107765198: OK (867bp). Scan... Found 7.\n",
            "[69/150] LOC107765261: OK (2575bp). Scan... Found 33.\n",
            "[70/150] LOC107765289: OK (1040bp). Scan... Found 10.\n",
            "[71/150] LOC107765377: OK (2998bp). Scan... Found 26.\n",
            "[72/150] LOC107765489: OK (1241bp). Scan... Found 10.\n",
            "[73/150] LOC107765507: OK (727bp). Scan... Found 4.\n",
            "[74/150] LOC107765515: OK (1496bp). Scan... Found 18.\n",
            "[75/150] LOC107765600: OK (1785bp). Scan... Found 16.\n",
            "[76/150] LOC107765678: SKIP -> Not found\n",
            "[77/150] LOC107765743: OK (1132bp). Scan... Found 8.\n",
            "[78/150] LOC107765752: OK (1039bp). Scan... Found 8.\n",
            "[79/150] LOC107765883: OK (1589bp). Scan... Found 12.\n",
            "[80/150] LOC107766025: OK (1289bp). Scan... Found 9.\n",
            "[81/150] LOC107766070: OK (1089bp). Scan... Found 10.\n",
            "[82/150] LOC107766295: OK (2259bp). Scan... Found 21.\n",
            "[83/150] LOC107766483: OK (3186bp). Scan... Found 31.\n",
            "[84/150] LOC107766665: OK (1668bp). Scan... Found 19.\n",
            "[85/150] LOC107766726: OK (2674bp). Scan... Found 17.\n",
            "[86/150] LOC107766775: OK (1300bp). Scan... Found 9.\n",
            "[87/150] LOC107766849: OK (1133bp). Scan... Found 12.\n",
            "[88/150] LOC107766940: OK (1529bp). Scan... Found 11.\n",
            "[89/150] LOC107767061: OK (1218bp). Scan... Found 8.\n",
            "[90/150] LOC107767062: OK (1216bp). Scan... Found 8.\n",
            "[91/150] LOC107767074: OK (987bp). Scan... Found 8.\n",
            "[92/150] LOC107767134: OK (1215bp). Scan... Found 8.\n",
            "[93/150] LOC107767209: OK (936bp). Scan... Found 10.\n",
            "[94/150] LOC107767275: OK (1255bp). Scan... Found 10.\n",
            "[95/150] LOC107767292: OK (1188bp). Scan... Found 18.\n",
            "[96/150] LOC107767314: OK (1073bp). Scan... Found 5.\n",
            "[97/150] LOC107767352: OK (1203bp). Scan... Found 10.\n",
            "[98/150] LOC107767390: OK (1382bp). Scan... Found 11.\n",
            "[99/150] LOC107767816: OK (1178bp). Scan... Found 8.\n",
            "[100/150] LOC107767974: OK (2489bp). Scan... Found 28.\n",
            "[101/150] LOC107768034: OK (869bp). Scan... Found 5.\n",
            "[102/150] LOC107768127: OK (1780bp). Scan... Found 30.\n",
            "[103/150] LOC107768198: OK (1460bp). Scan... Found 14.\n",
            "[104/150] LOC107768506: OK (2314bp). Scan... Found 20.\n",
            "[105/150] LOC107768591: OK (1169bp). Scan... Found 10.\n",
            "[106/150] LOC107768665: OK (759bp). Scan... Found 3.\n",
            "[107/150] LOC107768677: OK (1029bp). Scan... Found 4.\n",
            "[108/150] LOC107768795: OK (2118bp). Scan... Found 14.\n",
            "[109/150] LOC107768797: OK (2633bp). Scan... Found 36.\n",
            "[110/150] LOC107768822: OK (1276bp). Scan... Found 12.\n",
            "[111/150] LOC107768891: OK (1413bp). Scan... Found 13.\n",
            "[112/150] LOC107769001: OK (1430bp). Scan... Found 20.\n",
            "[113/150] LOC107769028: OK (1130bp). Scan... Found 9.\n",
            "[114/150] LOC107769068: OK (2436bp). Scan... Found 36.\n",
            "[115/150] LOC107769078: OK (1017bp). Scan... Found 15.\n",
            "[116/150] LOC107769123: OK (1452bp). Scan... Found 21.\n",
            "[117/150] LOC107769141: OK (805bp). Scan... Found 5.\n",
            "[118/150] LOC107769142: OK (899bp). Scan... Found 4.\n",
            "[119/150] LOC107769244: OK (1165bp). Scan... Found 17.\n",
            "[120/150] LOC107769814: OK (2717bp). Scan... Found 27.\n",
            "[121/150] LOC107769826: OK (1543bp). Scan... Found 19.\n",
            "[122/150] LOC107769887: OK (1635bp). Scan... Found 8.\n",
            "[123/150] LOC107769992: OK (2107bp). Scan... Found 16.\n",
            "[124/150] LOC107770065: OK (1839bp). Scan... Found 19.\n",
            "[125/150] LOC107770073: OK (2023bp). Scan... Found 19.\n",
            "[126/150] LOC107770077: OK (802bp). Scan... Found 3.\n",
            "[127/150] LOC107770118: OK (2133bp). Scan... Found 30.\n",
            "[128/150] LOC107770279: OK (1391bp). Scan... Found 8.\n",
            "[129/150] LOC107770326: OK (910bp). Scan... Found 4.\n",
            "[130/150] LOC107770507: OK (812bp). Scan... Found 7.\n",
            "[131/150] LOC107770624: OK (1260bp). Scan... Found 27.\n",
            "[132/150] LOC107770659: OK (2100bp). Scan... Found 22.\n",
            "[133/150] LOC107770743: OK (1157bp). Scan... Found 18.\n",
            "[134/150] LOC107770948: OK (1404bp). Scan... Found 16.\n",
            "[135/150] LOC107770988: OK (1210bp). Scan... Found 8.\n",
            "[136/150] LOC107771014: OK (2672bp). Scan... Found 22.\n",
            "[137/150] LOC107771050: OK (2159bp). Scan... Found 16.\n",
            "[138/150] LOC107771165: OK (1187bp). Scan... Found 7.\n",
            "[139/150] LOC107771217: OK (3126bp). Scan... Found 25.\n",
            "[140/150] LOC107771305: OK (1203bp). Scan... Found 7.\n",
            "[141/150] LOC107771425: OK (2269bp). Scan... Found 38.\n",
            "[142/150] LOC107771451: OK (648bp). Scan... Found 3.\n",
            "[143/150] LOC107771458: OK (1249bp). Scan... Found 11.\n",
            "[144/150] LOC107771551: OK (1356bp). Scan... Found 10.\n",
            "[145/150] LOC107771811: SKIP -> Not found\n",
            "[146/150] LOC107771860: OK (1819bp). Scan... Found 15.\n",
            "[147/150] LOC107771966: OK (1511bp). Scan... Found 16.\n",
            "[148/150] LOC107772017: OK (2468bp). Scan... Found 31.\n",
            "[149/150] LOC107772046: SKIP -> Not found\n",
            "[150/150] LOC107772182: OK (1023bp). Scan... Found 10.\n",
            "\n",
            "[SUCCESS] Mined data saved: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/data/dataset_Nicotiana_tabacum_150_20000.csv (1800 records)\n",
            "\n",
            "--- STEP 3: TRAINING MODELS (binary) ---\n",
            "\n",
            "--- STARTING MULTI-MODEL ML TRAINING (BINARY) ---\n",
            "      -> Data split: 2880 Train, 720 Test\n",
            "      -> Feature Engineering (3-5 gram char vectorizer)...\n",
            "\n",
            "      -> Training LogisticRegression...\n",
            "         Best Params: {'C': 0.1, 'solver': 'liblinear'}\n",
            "         Test Accuracy: 91.81% (3.3s)\n",
            "\n",
            "      -> Training RandomForest...\n",
            "         Best Params: {'max_depth': 20, 'n_estimators': 200}\n",
            "         Test Accuracy: 91.81% (38.3s)\n",
            "\n",
            "      -> Training SVM...\n",
            "         Best Params: {'C': 10, 'kernel': 'rbf'}\n",
            "         Test Accuracy: 95.56% (259.7s)\n",
            "\n",
            "      -> Training GradientBoosting...\n",
            "         Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "         Test Accuracy: 92.50% (45.4s)\n",
            "\n",
            "      --- MODEL LEADERBOARD ---\n",
            "             Model  Accuracy                                                 Best Params\n",
            "               SVM  0.955556                                  {'C': 10, 'kernel': 'rbf'}\n",
            "  GradientBoosting  0.925000 {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "      RandomForest  0.918056                      {'max_depth': 20, 'n_estimators': 200}\n",
            "LogisticRegression  0.918056                           {'C': 0.1, 'solver': 'liblinear'}\n",
            "\n",
            "      -> 🏆 WINNER: SVM (Acc: 95.56%)\n",
            "      -> Saving winner to: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/SVM_95.6_Nicotiana_tabacum.pkl\n",
            "\n",
            "--- STARTING TRANSFORMER RETRAINING (BINARY) ---\n",
            "      -> Base Model Source: nigelhartm/PlantBERT\n",
            "      -> Data split: 2880 Train, 720 Test\n",
            "      -> Detected 2 classes.\n",
            "      -> Loading Tokenizer from: nigelhartm/PlantBERT\n",
            "      -> Flexible Shape Strategy: PlantBERT (PosEmbed)\n",
            "      -> Using max sequence length: 512\n",
            "Map: 100% 2880/2880 [00:00<00:00, 3359.63 examples/s]\n",
            "Map: 100% 720/720 [00:00<00:00, 3571.16 examples/s]\n",
            "      -> Loading Model Weights from: nigelhartm/PlantBERT\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nigelhartm/PlantBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "      -> [Auto-Fix] Resizing model position embeddings from 128 to 512\n",
            "      -> Checkpoints will be saved to: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/checkpoints\n",
            "      -> [Config] Standard Model: Using BatchSize=16\n",
            "/content/plant-stress-regulator-predictor/scripts/ensemble_predictor.py:670: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "      -> Starting Training (this may take a while)...\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 1}.\n",
            "{'loss': 0.6415, 'grad_norm': 4.92810583114624, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 0.5241, 'grad_norm': 7.698270797729492, 'learning_rate': 1.92962962962963e-05, 'epoch': 0.11}\n",
            "{'loss': 0.3449, 'grad_norm': 5.742787837982178, 'learning_rate': 1.8925925925925928e-05, 'epoch': 0.17}\n",
            "{'loss': 0.2688, 'grad_norm': 4.857837200164795, 'learning_rate': 1.8555555555555557e-05, 'epoch': 0.22}\n",
            "{'loss': 0.1642, 'grad_norm': 5.585292816162109, 'learning_rate': 1.8185185185185186e-05, 'epoch': 0.28}\n",
            "{'loss': 0.443, 'grad_norm': 11.697392463684082, 'learning_rate': 1.7814814814814815e-05, 'epoch': 0.33}\n",
            "{'loss': 0.2861, 'grad_norm': 4.563651084899902, 'learning_rate': 1.7444444444444448e-05, 'epoch': 0.39}\n",
            "{'loss': 0.3179, 'grad_norm': 12.947868347167969, 'learning_rate': 1.7074074074074077e-05, 'epoch': 0.44}\n",
            "{'loss': 0.2878, 'grad_norm': 8.66834831237793, 'learning_rate': 1.6703703703703703e-05, 'epoch': 0.5}\n",
            "{'loss': 0.1693, 'grad_norm': 1.314393401145935, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.56}\n",
            "{'loss': 0.2708, 'grad_norm': 10.356456756591797, 'learning_rate': 1.5962962962962964e-05, 'epoch': 0.61}\n",
            "{'loss': 0.2881, 'grad_norm': 2.835861921310425, 'learning_rate': 1.5592592592592593e-05, 'epoch': 0.67}\n",
            "{'loss': 0.2591, 'grad_norm': 7.703196048736572, 'learning_rate': 1.5222222222222223e-05, 'epoch': 0.72}\n",
            "{'loss': 0.2546, 'grad_norm': 5.97143030166626, 'learning_rate': 1.4851851851851853e-05, 'epoch': 0.78}\n",
            "{'loss': 0.2309, 'grad_norm': 4.502984046936035, 'learning_rate': 1.4481481481481483e-05, 'epoch': 0.83}\n",
            "{'loss': 0.2366, 'grad_norm': 11.233132362365723, 'learning_rate': 1.4111111111111113e-05, 'epoch': 0.89}\n",
            "{'loss': 0.2241, 'grad_norm': 3.2608563899993896, 'learning_rate': 1.3740740740740741e-05, 'epoch': 0.94}\n",
            "{'loss': 0.3226, 'grad_norm': 8.289815902709961, 'learning_rate': 1.3370370370370372e-05, 'epoch': 1.0}\n",
            " 33% 180/540 [02:43<05:31,  1.09it/s]\n",
            "  0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/45 [00:00<00:06,  6.59it/s]\u001b[A\n",
            "  7% 3/45 [00:00<00:09,  4.58it/s]\u001b[A\n",
            "  9% 4/45 [00:00<00:10,  4.03it/s]\u001b[A\n",
            " 11% 5/45 [00:01<00:10,  3.75it/s]\u001b[A\n",
            " 13% 6/45 [00:01<00:10,  3.59it/s]\u001b[A\n",
            " 16% 7/45 [00:01<00:10,  3.48it/s]\u001b[A\n",
            " 18% 8/45 [00:02<00:10,  3.43it/s]\u001b[A\n",
            " 20% 9/45 [00:02<00:10,  3.40it/s]\u001b[A\n",
            " 22% 10/45 [00:02<00:10,  3.37it/s]\u001b[A\n",
            " 24% 11/45 [00:03<00:10,  3.37it/s]\u001b[A\n",
            " 27% 12/45 [00:03<00:09,  3.35it/s]\u001b[A\n",
            " 29% 13/45 [00:03<00:09,  3.34it/s]\u001b[A\n",
            " 31% 14/45 [00:03<00:09,  3.33it/s]\u001b[A\n",
            " 33% 15/45 [00:04<00:09,  3.32it/s]\u001b[A\n",
            " 36% 16/45 [00:04<00:08,  3.32it/s]\u001b[A\n",
            " 38% 17/45 [00:04<00:08,  3.31it/s]\u001b[A\n",
            " 40% 18/45 [00:05<00:08,  3.29it/s]\u001b[A\n",
            " 42% 19/45 [00:05<00:07,  3.29it/s]\u001b[A\n",
            " 44% 20/45 [00:05<00:07,  3.29it/s]\u001b[A\n",
            " 47% 21/45 [00:06<00:07,  3.29it/s]\u001b[A\n",
            " 49% 22/45 [00:06<00:07,  3.27it/s]\u001b[A\n",
            " 51% 23/45 [00:06<00:06,  3.27it/s]\u001b[A\n",
            " 53% 24/45 [00:06<00:06,  3.27it/s]\u001b[A\n",
            " 56% 25/45 [00:07<00:06,  3.29it/s]\u001b[A\n",
            " 58% 26/45 [00:07<00:05,  3.31it/s]\u001b[A\n",
            " 60% 27/45 [00:07<00:05,  3.31it/s]\u001b[A\n",
            " 62% 28/45 [00:08<00:05,  3.30it/s]\u001b[A\n",
            " 64% 29/45 [00:08<00:04,  3.30it/s]\u001b[A\n",
            " 67% 30/45 [00:08<00:04,  3.30it/s]\u001b[A\n",
            " 69% 31/45 [00:09<00:04,  3.30it/s]\u001b[A\n",
            " 71% 32/45 [00:09<00:03,  3.29it/s]\u001b[A\n",
            " 73% 33/45 [00:09<00:03,  3.29it/s]\u001b[A\n",
            " 76% 34/45 [00:10<00:03,  3.29it/s]\u001b[A\n",
            " 78% 35/45 [00:10<00:03,  3.29it/s]\u001b[A\n",
            " 80% 36/45 [00:10<00:02,  3.29it/s]\u001b[A\n",
            " 82% 37/45 [00:10<00:02,  3.29it/s]\u001b[A\n",
            " 84% 38/45 [00:11<00:02,  3.30it/s]\u001b[A\n",
            " 87% 39/45 [00:11<00:01,  3.29it/s]\u001b[A\n",
            " 89% 40/45 [00:11<00:01,  3.29it/s]\u001b[A\n",
            " 91% 41/45 [00:12<00:01,  3.29it/s]\u001b[A\n",
            " 93% 42/45 [00:12<00:00,  3.28it/s]\u001b[A\n",
            " 96% 43/45 [00:12<00:00,  3.30it/s]\u001b[A\n",
            " 98% 44/45 [00:13<00:00,  3.29it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.2329302430152893, 'eval_accuracy': 0.9138888888888889, 'eval_runtime': 13.6628, 'eval_samples_per_second': 52.698, 'eval_steps_per_second': 3.294, 'epoch': 1.0}\n",
            " 33% 180/540 [02:56<05:31,  1.09it/s]\n",
            "100% 45/45 [00:13<00:00,  3.31it/s]\u001b[A\n",
            "{'loss': 0.1541, 'grad_norm': 1.5574089288711548, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.06}\n",
            "{'loss': 0.1275, 'grad_norm': 2.3747780323028564, 'learning_rate': 1.2629629629629632e-05, 'epoch': 1.11}\n",
            "{'loss': 0.2331, 'grad_norm': 11.131683349609375, 'learning_rate': 1.225925925925926e-05, 'epoch': 1.17}\n",
            "{'loss': 0.2043, 'grad_norm': 2.5476386547088623, 'learning_rate': 1.188888888888889e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2341, 'grad_norm': 0.1973382979631424, 'learning_rate': 1.151851851851852e-05, 'epoch': 1.28}\n",
            "{'loss': 0.0565, 'grad_norm': 5.955150127410889, 'learning_rate': 1.114814814814815e-05, 'epoch': 1.33}\n",
            "{'loss': 0.1227, 'grad_norm': 4.6416425704956055, 'learning_rate': 1.0777777777777778e-05, 'epoch': 1.39}\n",
            "{'loss': 0.1949, 'grad_norm': 7.027186393737793, 'learning_rate': 1.0407407407407408e-05, 'epoch': 1.44}\n",
            "{'loss': 0.1315, 'grad_norm': 0.4787767827510834, 'learning_rate': 1.003703703703704e-05, 'epoch': 1.5}\n",
            "{'loss': 0.1327, 'grad_norm': 5.059206962585449, 'learning_rate': 9.666666666666667e-06, 'epoch': 1.56}\n",
            "{'loss': 0.1133, 'grad_norm': 0.6410242319107056, 'learning_rate': 9.296296296296296e-06, 'epoch': 1.61}\n",
            "{'loss': 0.1477, 'grad_norm': 8.753158569335938, 'learning_rate': 8.925925925925927e-06, 'epoch': 1.67}\n",
            "{'loss': 0.1073, 'grad_norm': 11.916938781738281, 'learning_rate': 8.555555555555556e-06, 'epoch': 1.72}\n",
            "{'loss': 0.0833, 'grad_norm': 0.0860581323504448, 'learning_rate': 8.185185185185187e-06, 'epoch': 1.78}\n",
            "{'loss': 0.1796, 'grad_norm': 16.865680694580078, 'learning_rate': 7.814814814814816e-06, 'epoch': 1.83}\n",
            "{'loss': 0.1048, 'grad_norm': 15.679056167602539, 'learning_rate': 7.444444444444445e-06, 'epoch': 1.89}\n",
            "{'loss': 0.1285, 'grad_norm': 12.464615821838379, 'learning_rate': 7.074074074074074e-06, 'epoch': 1.94}\n",
            "{'loss': 0.1272, 'grad_norm': 4.267512321472168, 'learning_rate': 6.703703703703704e-06, 'epoch': 2.0}\n",
            " 67% 360/540 [05:55<02:46,  1.08it/s]\n",
            "  0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/45 [00:00<00:06,  6.46it/s]\u001b[A\n",
            "  7% 3/45 [00:00<00:09,  4.53it/s]\u001b[A\n",
            "  9% 4/45 [00:00<00:10,  3.96it/s]\u001b[A\n",
            " 11% 5/45 [00:01<00:10,  3.69it/s]\u001b[A\n",
            " 13% 6/45 [00:01<00:10,  3.55it/s]\u001b[A\n",
            " 16% 7/45 [00:01<00:11,  3.45it/s]\u001b[A\n",
            " 18% 8/45 [00:02<00:10,  3.41it/s]\u001b[A\n",
            " 20% 9/45 [00:02<00:10,  3.37it/s]\u001b[A\n",
            " 22% 10/45 [00:02<00:10,  3.33it/s]\u001b[A\n",
            " 24% 11/45 [00:03<00:10,  3.32it/s]\u001b[A\n",
            " 27% 12/45 [00:03<00:09,  3.32it/s]\u001b[A\n",
            " 29% 13/45 [00:03<00:09,  3.30it/s]\u001b[A\n",
            " 31% 14/45 [00:03<00:09,  3.30it/s]\u001b[A\n",
            " 33% 15/45 [00:04<00:09,  3.30it/s]\u001b[A\n",
            " 36% 16/45 [00:04<00:08,  3.29it/s]\u001b[A\n",
            " 38% 17/45 [00:04<00:08,  3.30it/s]\u001b[A\n",
            " 40% 18/45 [00:05<00:08,  3.30it/s]\u001b[A\n",
            " 42% 19/45 [00:05<00:07,  3.30it/s]\u001b[A\n",
            " 44% 20/45 [00:05<00:07,  3.29it/s]\u001b[A\n",
            " 47% 21/45 [00:06<00:07,  3.29it/s]\u001b[A\n",
            " 49% 22/45 [00:06<00:07,  3.28it/s]\u001b[A\n",
            " 51% 23/45 [00:06<00:06,  3.27it/s]\u001b[A\n",
            " 53% 24/45 [00:07<00:06,  3.26it/s]\u001b[A\n",
            " 56% 25/45 [00:07<00:06,  3.25it/s]\u001b[A\n",
            " 58% 26/45 [00:07<00:05,  3.25it/s]\u001b[A\n",
            " 60% 27/45 [00:07<00:05,  3.26it/s]\u001b[A\n",
            " 62% 28/45 [00:08<00:05,  3.25it/s]\u001b[A\n",
            " 64% 29/45 [00:08<00:04,  3.24it/s]\u001b[A\n",
            " 67% 30/45 [00:08<00:04,  3.25it/s]\u001b[A\n",
            " 69% 31/45 [00:09<00:04,  3.26it/s]\u001b[A\n",
            " 71% 32/45 [00:09<00:03,  3.28it/s]\u001b[A\n",
            " 73% 33/45 [00:09<00:03,  3.28it/s]\u001b[A\n",
            " 76% 34/45 [00:10<00:03,  3.28it/s]\u001b[A\n",
            " 78% 35/45 [00:10<00:03,  3.29it/s]\u001b[A\n",
            " 80% 36/45 [00:10<00:02,  3.29it/s]\u001b[A\n",
            " 82% 37/45 [00:10<00:02,  3.29it/s]\u001b[A\n",
            " 84% 38/45 [00:11<00:02,  3.29it/s]\u001b[A\n",
            " 87% 39/45 [00:11<00:01,  3.28it/s]\u001b[A\n",
            " 89% 40/45 [00:11<00:01,  3.28it/s]\u001b[A\n",
            " 91% 41/45 [00:12<00:01,  3.29it/s]\u001b[A\n",
            " 93% 42/45 [00:12<00:00,  3.28it/s]\u001b[A\n",
            " 96% 43/45 [00:12<00:00,  3.29it/s]\u001b[A\n",
            " 98% 44/45 [00:13<00:00,  3.29it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.2577454745769501, 'eval_accuracy': 0.9361111111111111, 'eval_runtime': 13.7408, 'eval_samples_per_second': 52.399, 'eval_steps_per_second': 3.275, 'epoch': 2.0}\n",
            " 67% 360/540 [06:09<02:46,  1.08it/s]\n",
            "100% 45/45 [00:13<00:00,  3.30it/s]\u001b[A\n",
            "{'loss': 0.1025, 'grad_norm': 18.503660202026367, 'learning_rate': 6.333333333333333e-06, 'epoch': 2.06}\n",
            "{'loss': 0.1547, 'grad_norm': 2.9879086017608643, 'learning_rate': 5.962962962962963e-06, 'epoch': 2.11}\n",
            "{'loss': 0.0493, 'grad_norm': 5.583946704864502, 'learning_rate': 5.5925925925925926e-06, 'epoch': 2.17}\n",
            "{'loss': 0.0405, 'grad_norm': 0.11670217663049698, 'learning_rate': 5.2222222222222226e-06, 'epoch': 2.22}\n",
            "{'loss': 0.0673, 'grad_norm': 20.71099281311035, 'learning_rate': 4.851851851851852e-06, 'epoch': 2.28}\n",
            "{'loss': 0.0157, 'grad_norm': 8.6860990524292, 'learning_rate': 4.481481481481482e-06, 'epoch': 2.33}\n",
            "{'loss': 0.0432, 'grad_norm': 2.078437566757202, 'learning_rate': 4.111111111111111e-06, 'epoch': 2.39}\n",
            "{'loss': 0.0831, 'grad_norm': 2.5954573154449463, 'learning_rate': 3.740740740740741e-06, 'epoch': 2.44}\n",
            "{'loss': 0.0778, 'grad_norm': 13.826349258422852, 'learning_rate': 3.3703703703703705e-06, 'epoch': 2.5}\n",
            "{'loss': 0.0119, 'grad_norm': 0.10766218602657318, 'learning_rate': 3e-06, 'epoch': 2.56}\n",
            "{'loss': 0.0343, 'grad_norm': 9.214272499084473, 'learning_rate': 2.6296296296296297e-06, 'epoch': 2.61}\n",
            "{'loss': 0.0369, 'grad_norm': 24.621503829956055, 'learning_rate': 2.2592592592592592e-06, 'epoch': 2.67}\n",
            "{'loss': 0.0856, 'grad_norm': 25.041967391967773, 'learning_rate': 1.888888888888889e-06, 'epoch': 2.72}\n",
            "{'loss': 0.0938, 'grad_norm': 17.469886779785156, 'learning_rate': 1.5185185185185186e-06, 'epoch': 2.78}\n",
            "{'loss': 0.0934, 'grad_norm': 2.916785955429077, 'learning_rate': 1.1481481481481482e-06, 'epoch': 2.83}\n",
            "{'loss': 0.0745, 'grad_norm': 0.09240972995758057, 'learning_rate': 7.777777777777779e-07, 'epoch': 2.89}\n",
            "{'loss': 0.0424, 'grad_norm': 0.24119578301906586, 'learning_rate': 4.074074074074075e-07, 'epoch': 2.94}\n",
            "{'loss': 0.0478, 'grad_norm': 0.2631742060184479, 'learning_rate': 3.703703703703704e-08, 'epoch': 3.0}\n",
            "100% 540/540 [09:07<00:00,  1.08it/s]\n",
            "  0% 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/45 [00:00<00:06,  6.52it/s]\u001b[A\n",
            "  7% 3/45 [00:00<00:09,  4.57it/s]\u001b[A\n",
            "  9% 4/45 [00:00<00:10,  4.00it/s]\u001b[A\n",
            " 11% 5/45 [00:01<00:10,  3.74it/s]\u001b[A\n",
            " 13% 6/45 [00:01<00:10,  3.59it/s]\u001b[A\n",
            " 16% 7/45 [00:01<00:10,  3.48it/s]\u001b[A\n",
            " 18% 8/45 [00:02<00:10,  3.43it/s]\u001b[A\n",
            " 20% 9/45 [00:02<00:10,  3.41it/s]\u001b[A\n",
            " 22% 10/45 [00:02<00:10,  3.38it/s]\u001b[A\n",
            " 24% 11/45 [00:03<00:10,  3.35it/s]\u001b[A\n",
            " 27% 12/45 [00:03<00:09,  3.33it/s]\u001b[A\n",
            " 29% 13/45 [00:03<00:09,  3.33it/s]\u001b[A\n",
            " 31% 14/45 [00:03<00:09,  3.32it/s]\u001b[A\n",
            " 33% 15/45 [00:04<00:09,  3.31it/s]\u001b[A\n",
            " 36% 16/45 [00:04<00:08,  3.30it/s]\u001b[A\n",
            " 38% 17/45 [00:04<00:08,  3.29it/s]\u001b[A\n",
            " 40% 18/45 [00:05<00:08,  3.30it/s]\u001b[A\n",
            " 42% 19/45 [00:05<00:07,  3.29it/s]\u001b[A\n",
            " 44% 20/45 [00:05<00:07,  3.29it/s]\u001b[A\n",
            " 47% 21/45 [00:06<00:07,  3.29it/s]\u001b[A\n",
            " 49% 22/45 [00:06<00:07,  3.28it/s]\u001b[A\n",
            " 51% 23/45 [00:06<00:06,  3.28it/s]\u001b[A\n",
            " 53% 24/45 [00:06<00:06,  3.30it/s]\u001b[A\n",
            " 56% 25/45 [00:07<00:06,  3.29it/s]\u001b[A\n",
            " 58% 26/45 [00:07<00:05,  3.30it/s]\u001b[A\n",
            " 60% 27/45 [00:07<00:05,  3.29it/s]\u001b[A\n",
            " 62% 28/45 [00:08<00:05,  3.28it/s]\u001b[A\n",
            " 64% 29/45 [00:08<00:04,  3.26it/s]\u001b[A\n",
            " 67% 30/45 [00:08<00:04,  3.26it/s]\u001b[A\n",
            " 69% 31/45 [00:09<00:04,  3.26it/s]\u001b[A\n",
            " 71% 32/45 [00:09<00:03,  3.26it/s]\u001b[A\n",
            " 73% 33/45 [00:09<00:03,  3.25it/s]\u001b[A\n",
            " 76% 34/45 [00:10<00:03,  3.28it/s]\u001b[A\n",
            " 78% 35/45 [00:10<00:03,  3.29it/s]\u001b[A\n",
            " 80% 36/45 [00:10<00:02,  3.29it/s]\u001b[A\n",
            " 82% 37/45 [00:10<00:02,  3.30it/s]\u001b[A\n",
            " 84% 38/45 [00:11<00:02,  3.30it/s]\u001b[A\n",
            " 87% 39/45 [00:11<00:01,  3.30it/s]\u001b[A\n",
            " 89% 40/45 [00:11<00:01,  3.30it/s]\u001b[A\n",
            " 91% 41/45 [00:12<00:01,  3.30it/s]\u001b[A\n",
            " 93% 42/45 [00:12<00:00,  3.30it/s]\u001b[A\n",
            " 96% 43/45 [00:12<00:00,  3.31it/s]\u001b[A\n",
            " 98% 44/45 [00:13<00:00,  3.31it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.2746453881263733, 'eval_accuracy': 0.9333333333333333, 'eval_runtime': 13.677, 'eval_samples_per_second': 52.643, 'eval_steps_per_second': 3.29, 'epoch': 3.0}\n",
            "100% 540/540 [09:21<00:00,  1.08it/s]\n",
            "100% 45/45 [00:13<00:00,  3.33it/s]\u001b[A\n",
            "{'train_runtime': 564.1907, 'train_samples_per_second': 15.314, 'train_steps_per_second': 0.957, 'train_loss': 0.1717033722196464, 'epoch': 3.0}\n",
            "100% 540/540 [09:24<00:00,  1.04s/it]\n",
            "100% 45/45 [00:13<00:00,  3.39it/s]\n",
            "      -> Final Evaluation: {'eval_loss': 0.2577454745769501, 'eval_accuracy': 0.9361111111111111, 'eval_runtime': 13.6661, 'eval_samples_per_second': 52.685, 'eval_steps_per_second': 3.293, 'epoch': 3.0}\n",
            "      -> Saving PlantBERT to /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum\n",
            "\n",
            "--- STEP 4: EVALUATION ---\n",
            "\n",
            "--- RUNNING FINAL ENSEMBLE PREDICTION ---\n",
            "      -> getting ML probabilities...\n",
            "      -> getting PlantBERT probabilities...\n",
            "         [INFO] Using device: cuda\n",
            "      -> Saved to Final_Ensemble_Predictions.csv\n",
            "      -> Final Predictions saved to: /content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python stress_predictor/main.py \\\n",
        "  --input /content/plant-stress-regulator-predictor/software_test/random_seq_test/random_2kb.fasta \\\n",
        "  --rg \\\n",
        "  --model-path \"/content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr0NixybzdYq",
        "outputId": "d87100b3-446d-4563-9832-eb2c43dbcc8f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run ID: run_20260113_150112_region\n",
            "Output directory: runs/run_20260113_150112_region\n",
            "Using device: cuda\n",
            "2026-01-13 15:01:13.037084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768316473.056756   28523 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768316473.063047   28523 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768316473.079917   28523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768316473.079950   28523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768316473.079955   28523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768316473.079959   28523 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-13 15:01:13.085376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Model max length: 512\n",
            "Found 0 stress regions.\n",
            "Predictions and HTML report saved to runs/run_20260113_150112_region\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r PlantBERT_93.6_Nicotiana_tabacum.zip \\\n",
        "/content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuxKG7Bx4Oob",
        "outputId": "d5c20c22-84be-43bc-80ad-26f3a597d4ac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/ (stored 0%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/tokenizer.json (deflated 87%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/model.safetensors (deflated 7%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/config.json (deflated 49%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/special_tokens_map.json (deflated 37%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/training_args.bin (deflated 54%)\n",
            "  adding: content/plant-stress-regulator-predictor/runs/run_20260113_144012_Nicotiana_tabacum_plantbert/models/PlantBERT_93.6_Nicotiana_tabacum/tokenizer_config.json (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"PlantBERT_93.6_Nicotiana_tabacum.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9OKCCTDA4Stb",
        "outputId": "adcba2ed-a2a9-46d9-b402-11512fb48033"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_67365bbe-b2d0-47d8-a0a5-41c3bf5c1ba1\", \"PlantBERT_93.6_Nicotiana_tabacum.zip\", 225942054)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}